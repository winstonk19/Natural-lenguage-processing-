{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eSLz7iJ97N2A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f95c5acf8c3e89e0b0e482c04e0b8abf",
          "grade": false,
          "grade_id": "cell-e98be1092b48b377",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FAt9Or3F7GU2"
      },
      "source": [
        "# Sprint Challenge\n",
        "## *Data Science Sprint 13*\n",
        "\n",
        "After a sprint of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). The data is sampled for you to something more manageable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge.\n",
        "\n",
        "## Challenge Objectives\n",
        "Successfully complete all these objectives to earn full credit.\n",
        "\n",
        "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
        "\n",
        "There are 8 total possible points in this sprint challenge.\n",
        "\n",
        "\n",
        "There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on Yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu.\n",
        "\n",
        "3) **Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section).**\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a0fb09b9e122fc2f2a2baae91a22a818",
          "grade": false,
          "grade_id": "cell-e6c3d2173420a581",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "GdJEiXMX7GU5"
      },
      "source": [
        "### Part 0: Import Necessary Packages\n",
        "For this section, you will need to import:\n",
        "- `spacy`\n",
        "- `Pandas`\n",
        "- `Seaborn`\n",
        "- `Matplotlib`\n",
        "- `NearestNeighbors`\n",
        "- `Pipeline`\n",
        "- `TfidfVectorizer`\n",
        "- `KneighborsClassifier`\n",
        "- `GridSearchCV`\n",
        "- `corpora`\n",
        "- `LdaModel`\n",
        "- `gensim`\n",
        "- `re`\n",
        "\n",
        "> **Note: This assignment is optimized to work with these specific packages. You can use import different packages, but note that this may affect how CodeGrade works, and may cause CodeGrade to fail.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6Hx0jHg7WUY",
        "outputId": "35d99897-f29a-47f4-eff7-035653ae7468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB6j_emB7WF4",
        "outputId": "38fe9e02-1f31-42ba-fe9f-8ee19e1da24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.1)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (71.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.14.1)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8d3d0719eecd5609256125d84cc4218a",
          "grade": false,
          "grade_id": "cell-b29df5c5bfb8c0d8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "iJoC3Z2i7GU5"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "import re\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6b8ad4a1ac317df7b82aced26eee406f",
          "grade": true,
          "grade_id": "cell-be1ef923d085ceb5",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4EthUSf7GU6",
        "outputId": "a4737187-42af-4ae4-c3ce-6ee5738113c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Visible Testing\n",
        "assert pd.__package__ == 'pandas'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "11b700564f5d76c1ec246d8fece821c1",
          "grade": false,
          "grade_id": "cell-c94bee05bece8c59",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "N7Cl3Uar7GU6"
      },
      "source": [
        "\n",
        "\n",
        "### Part 0: Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "150e28699f961709cb59be5e0f8ddbe0",
          "grade": false,
          "grade_id": "cell-395851cd95d17235",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmy2Et1x7GU7",
        "outputId": "abd9a139-854e-4fec-b969-422d4a145cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load reviews from URL\n",
        "data_url = 'https://raw.githubusercontent.com/bloominstituteoftechnology/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
        "\n",
        "# Import data into a DataFrame named df\n",
        "# YOUR CODE HERE\n",
        "df = pd.read_json(data_url, lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "356579363f311da83f4ef7abaf3c9212",
          "grade": true,
          "grade_id": "cell-cb5006475e42b8f9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sckuMO97GU7",
        "outputId": "d344f653-c71c-4fd3-e0bd-adb06e165f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Visible Testing\n",
        "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
        "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "aedd47e33e28a74846b51e236deef316",
          "grade": false,
          "grade_id": "cell-27dc6b438d2f2722",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BWBVYx7u7GU7"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- Accept one document at a time\n",
        "- Return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week.\n",
        "\n",
        "**TO PASS CODEGRADE RUNTIME:**\n",
        "- Do not run your tokenize function more than one time in your notebook! It is not needed until Part 4!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xxcahh-7GU7",
        "outputId": "0ac8dd94-99d7-499e-b754-d7f664aaf668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
        "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
        "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4837ed2a1cc13057ba40203859d46ff6",
          "grade": false,
          "grade_id": "cell-3d570d5a1cd6cb64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIm-WhuH7GU8",
        "outputId": "21ae74b8-87a6-4809-8ba2-b902c524544f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def tokenize(doc):\n",
        "  doc = nlp(doc)\n",
        "  tokens = []\n",
        "\n",
        "  for token in doc:\n",
        "    if (token.is_punct == False) and (token.is_stop == False) and (token.is_space == False):\n",
        "      tokens.append(token.lemma_)\n",
        "\n",
        "\n",
        "\n",
        "  return [token.lower() for token in tokens]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2181ca9d36070260b1f75dcfd9e58965",
          "grade": true,
          "grade_id": "cell-02da164f6fbe730a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my-an4Pq7GU8",
        "outputId": "807d6cd6-a693-43e1-a4bf-09499c28e3bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "'''Testing'''\n",
        "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d4137c3ea2fa84821d1dbf1b28dde6dd",
          "grade": false,
          "grade_id": "cell-ef13337bc7694c52",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-COhYCah7GU8"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
        "    * Name that doc-term matrix `dtm`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fefca7db0abb1474d316d6aa24e032f8",
          "grade": false,
          "grade_id": "cell-0e96491cb529202c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHL6_LEJ7GU8",
        "outputId": "e9f57da3-ab52-4d60-974b-5bc78e4d0dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.58 s, sys: 28.5 ms, total: 3.6 s\n",
            "Wall time: 7.39 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf = tfidf.fit(df.text)\n",
        "dtm= tfidf.transform(df.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "86048b7ea6cb011227aefa5a8f7a9e65",
          "grade": false,
          "grade_id": "cell-33c058ea193687c3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_v3tN1tw7GU8"
      },
      "source": [
        "\n",
        "2. Write a fake review. Assign the text of the review to an object called `fake_review`.\n",
        "3. Query the fake review for the 10 most similar reviews, print the text of the reviews.\n",
        "    - Given the size of the dataset, use `NearestNeighbors` model for this. Name the model `nn`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_review = \"\"\" This product is bad for anyone who is not interested on having a great experience. Here you are able to see the fetures that other machine lacks.\n",
        "                   Of course if tou are someone who is just looking to use it for work this is not the computer for you since you will be waisting money in something you don't need\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veRbnTco8Zm4",
        "outputId": "778dc98f-e749-433f-e80c-7f1c60003b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f6aa466983420c836879d744ffa6c9a8",
          "grade": false,
          "grade_id": "cell-3d5bc610a8ec6b24",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "HuNf3cq77GU8",
        "outputId": "e1c80e31-cfb3-4cfa-b50c-ba50863bb6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(n_neighbors=10)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(n_neighbors=10)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Create and fit a NearestNeighbors model named \"nn\"\n",
        "# YOUR CODE HERE\n",
        "top_n_neighbors = 10\n",
        "nn = NearestNeighbors(n_neighbors=top_n_neighbors)\n",
        "nn.fit(dtm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
          "grade": true,
          "grade_id": "cell-c43704dcff67e99b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX9IFoF77GU8",
        "outputId": "cac8bacd-e2be-4052-8252-3b6c1ec1a414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "'''Testing.'''\n",
        "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
        "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
          "grade": false,
          "grade_id": "cell-496203e8746296ca",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1OVlmEj7GU9",
        "outputId": "019e6c83-5913-46f5-afaa-a6097e80a81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Create a fake review and find the 10 most similar reviews\n",
        "\n",
        "# YOUR CODE HERE\n",
        "fake_review_dtm = tfidf.transform([fake_review])\n",
        "n_dis, n_ind = nn.kneighbors(fake_review_dtm)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index in n_ind[0]:\n",
        "    print(df['text'].iloc[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p8xaiFr9j-n",
        "outputId": "7bac1dea-5f9a-4a87-be16-c6505b8046d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the people that said service was Excellent, I question your opinion in Excellence.\n",
            "   The food here is Pretty good if you're really into sushi. The Vampire roll is my fave and has garlic ponzu sauce on top, they have Great Udon and Miso. LOVE their Poke and seaweed salad and they have a few other good ones too AND out of the 6 times I've gone, I never had to wait for a table. \n",
            "   BIG But however, Absolutely Trust in these words and the others that say the service is not good and the woman that are waiting on you are mostly standing in the back doing nothing. I have not sat at the bar yet.  \n",
            "   \n",
            "   If you have somewhere to be, do not come here. It's the slowest sushi restaurant I've been to in LV and I've been to at least 10 in this city. Look forward to them bringing someone else's order to your table, not checking up on you for water until after it's gone (not every time but enough times to be parched), they take your AYCE card away and don't return it so you can order more; you have to ask for it back. And thats about it. They're pleasant though, not mean at all, they just don't have things very organized and don't tend to you as they should.  \n",
            "\n",
            "  Great food, bad service. I have not been there once out of 6 times and the service changed. Literally. I don't just bash restaurants and I hope you see I'm not doing that. I'm not hard to please and LOVE sushi. I wish SO much the service was better b.c the food really is good, it's just not here. Thats the only reason for the 3 stars, the food. So, go for the food and if you're hungry, expect to be there for a bit.\n",
            "This place is a mom and pop type of place. I come here in between work shifts. The staff is awesome the service is quick and the food is good. Prices aren't bad either. You definitely get what you pay for. I think the breakfast specials are the best prices in the area so if you are looking for all of the above, this is the place to go.\n",
            "Riazzi's is the type of place that you need to know what you are doing and what to expect to enjoy it.  Other reviewers are right on about some of the negatives:  the decor is horrible and certain menu items are fine but not impressive.\n",
            "\n",
            "Here is what you need to know to dig it:\n",
            "\n",
            "1.  Sit in the bar-- it has a cooler vibe than the dining room (kind of mobstery)\n",
            "2.  Order seafood or one of the specialty dinners.  Don't fill up on bread or salad, the bread is great, and the salad is the old school iceberge lettuce with beets and pepperochinis.\n",
            "3.  If you want pizza, they make great pizza, but keep it simple, this is not the type of pizza you want to ruin with a ton of toppings.  We usually order it with just onions or just garlic. I wouldn't add pepperoni, it just isn't that type of pizza.  If you don't like onions, you don't know anything about food, and should eat every meal at Applebee's.\n",
            "4.  I also recommend the chicken Marsala, but I have never had it anywhere else, so it is hard to say if it is a good one.  I like it, and I am a fan of food.\n",
            "5.  The prices are reasonable to cheap for a sit down place.  Can't go wrong with that!\n",
            "\n",
            "It's a good place!  Don't let the other review fool you, just be prepared, and don't expect Olive Garden.  This is real food.  I think some people have forgotten what real food is.\n",
            "This is the perfect neighborhood bar!  The wait staff is friendly, the food is amazing, and if the game you're looking for isn't on, they will do everything they can to take care of you!  Great experience.\n",
            "If you're looking for something fun and different to do in Vegas try this place out. It's also a great place to escape the heat! You don't need to actually purchase any Yelp or Groupon deals to get the promotion. Just make sure you mention it to them when you're paying. After watching a short intro you are all set to go. The employees walk around and can give you pointers, but it's really trial and error on your own. They could use some more equipment though. They only had a couple of compound bows and arm guards for people to use. I like the casual atmosphere of the place. I've been to other archery ranges and you feel like someone is constantly watching you and therefore making you even more nervous. If you're not sure how much time you have left, there's a board above the glass window with a countdown of your session.\n",
            "Size:\n",
            "\n",
            "11 PEOPLE.\n",
            "\n",
            "That's right, 11 people in a 2 bedroom suite. Was there enough room? Kind of. There are 2 queen beds and 2 pullout couches. With 2 people on each, that left 3 people out. 1 person slept on a couch that didn't fold out. The other 2 slept on the floor. If you don't want anyone sleeping on the floor, you can fit 9 people in a 2 bedroom suite. You might be able to fit more if you put 3 to a bed, but it gets really crowded fast. Other then sleeping quarters, the room was a good size. You can have people watching TV on the couch while other people are watching TV in the other room or playing card games on the dining room table.\n",
            "\n",
            "Room Amenities:\n",
            "\n",
            "*The Good\n",
            "\n",
            "The microwave and full fridge came in handy. The microwave is hard to understand at first (you have to use a knob to select cooking time) but after a while, you get the hang of it. Also, the full size fridge fit all our alcohol and food and has an ice dispenser built in. Maybe that's why they put the ice machines so far apart. All the TV's worked fine and the giant projector was cool. The Jacuzzi will fit about 2 - 4 people, depending on the size of the person. We never used the washer or dryer. \n",
            "\n",
            "\n",
            "*The Bad\n",
            "\n",
            "The electric stove was pretty bad. Unless you have experience using an electric stove, I would not use it at all. We burned everything and the pans and pots they supply where very cheap. I would recommend to just microwaving everything. One of the shower heads would spray water everywhere when you first turned it on. Only 3 trashcans in the whole place. For those getting a studio suite, I suggest you bring a couple of plastic grocery bags and place the full bags in the hall for the maids to pick up.\n",
            "\n",
            "*Atmosphere:\n",
            "\n",
            "This hotel is packed with young people. I would say the median age is 24. If you are looking for a hotel for kids, this is not the hotel for you. If you are looking for a hotel to come and party with your young friends, then this hotel is perfect.\n",
            "\n",
            "*Parking:\n",
            "\n",
            "I don't know why everyone on here is complaining about parking. There is parking directly behind the PH West Gate. Yes it is not valet (which sucks), but the self parking takes you directly to the front desk. After you park in the structure and walk into the Hotel, it's directly to your right. It literally took us 1 minute to walk from our car to the check in line.\n",
            "\n",
            "*Gambling:\n",
            "\n",
            "I like to gamble. Not much, but I always put a few hundred away to lose. I found it to be a pain in the buns to walk through the mall area to get to the PH Casino. It's not a long walk, but it can be a pain to get through when it is packed full of people, especially on the weekends.  \n",
            "\n",
            "\n",
            "I liked this hotel. I would probably would have loved it if I were single and 21. Since the rooms are spacious and somewhat affordable, it's a good spot for a young bachelor or bachelorette party.\n",
            "\n",
            "In the end, I still prefer the Palazzo, which has a \"classy\" party feel. The PH Westgate feels like a \"college house party\".\n",
            "Location: Situated in an industrial/business area in Mississauga, the OCCS is a bit confusing to find if you are not sure what you are looking for.  The building is in the BACK with ample parking spaces. The facility was NOT heated so if you are going in the fall (like we did) wear a sweater or something.  It was freezing and definitely affected the mobility in my hands for archery.\n",
            "\n",
            "Experience: You are given a basic composite bow to shoot with and three arrows to shoot.  They will first find out if you are left or right eye dominant and have you shooting from that respective hand.  This was uncomfortable for me at first since I used to teach and I was used to shooting with my right arm despite being left eye dominant.  However, I got over it. You also have the option of wearing an arm brace and to use a finger tab if necessary.  \n",
            "\n",
            "If you have done archery before and you are going as a group, prepared to be bored.  The \"instructional time\" takes forever and gets very repetitive. Going over safety procedures are extremely important but if you are more experienced, you still have to WAIT for everyone else to get their lesson. Have friends who are always late? Or others in your group who do things slowly?  You'll have to wait for them too if they start shooting later than you or if they are slow to \"gather their things\" on the range. That said, if you are a newbie, don't worry... they take things very slow.\n",
            "\n",
            "Personally, I felt like it went by too fast and the experience too structured.  Our group spent about half the time listening to instructions and the other half shooting.  However, I did enjoy my time here and it was a fun non-typical activity to do as a group.  I would return to the OCCS, but maybe for fencing next time\n",
            "\n",
            "Price: A good deal if you go in a group.  We were a large group of 16 and ended up paying just over $20 a head.  As the organizer, however, you have to put down a deposit to confirm the date.  One thing that was particularly inconvenient is that they accommodate many groups but their payment system is so inefficient.  It is difficult to give your friends an accurate estimate of how much it costs per person ahead of time because 1) it depends on how many people show up the day of and 2) they want payment up front.  This does not make sense.  If you have late people, they will still have to pay full price (their fault for being late) but you'd have to adjust the price at the end anyway.  Why not WAIT until the end before finalizing the group's rate/price and then dividing it by the amount of people that are there. \n",
            "\n",
            "Our birthday boy was the host, and he had to deposit and pay for everyone up front. Friends can try to step in, but in my opinion, working out a smoother payment system for groups prevents a lot of headaches and recalculating at the end.\n",
            "\n",
            "Overall: It was a very enjoyable outing and a reasonable price.  Would likely return to the OCCS to explore other sports but the centre does have some room for improvement.\n",
            "I lived near this IKEA for 5 years...and I loved it. But I also knew when to stay far, far away.\n",
            "\n",
            "Here's some tips from a local:\n",
            "\n",
            "1. If you go on a weekend, you're going to hate the crowd- think busy Walmart times 10. People travel from all over the southeast to go to this IKEA. So, if you can con your employer into giving you a day off work to make the trip, you will have a much more pleasant time here. You'll actually be able to think without dealing with screaming kids everywhere.\n",
            "\n",
            "2. BYOB. Bag. Bring your own bag. I don't think they allow beer in here, but I wish they did so the crowds would be more tolerable. I made the mistake of buying all my kitchen supplies without bringing a bag and I had to spend a few extra bucks to buy reusable IKEA bags that are so large I will probably never reuse.\n",
            "\n",
            "3. Take lots of photos. The descriptions of items are SO confusing. You have to match up the number on the item you saw in the showroom with the number on the shelf in the warehouse. This is fine if you know what product the number you're taking a picture of corresponds to. Otherwise you'll end up like me: having tons of pictures of numbers and not knowing what they go to. You'll run around the whole warehouse trying to find the stuff you wanted to buy.\n",
            "\n",
            "4. Drive a big truck. If you know you're buying lots of furniture, U-Haul it up and load all your things flawlessly. If you drive a Sedan, forget about bringing any large furniture home with you.\n",
            "\n",
            "5. Make a friend who knows how to put together furniture. The instructions are just poorly drawn diagrams and no written words. Youtube will be your best friend in this situation.\n",
            "\n",
            "6. Eat in the cafeterias. When I was in college, we would go get the $2 full breakfast after a night of drinking (if we woke up in time). Also, swedish meatballs salmon and LINGONBERRY are something you won't want to miss. When I was between paychecks in college, the $1.50 hotdog meal was a godsend. \n",
            "\n",
            "If you follow these tips, IKEA can be a cheap place to get trendy furniture. If not, it might end up being hell. Just do these 6 things and you'll love it.\n",
            "The future is here! This is a perfect activity for a date night or first date. Or, just something fun to do with a buddy or group of friends.\n",
            "\n",
            "This is for you if: You are into tech, cool gadgets, fun stuff, mind expanding experiences, games and fun.\n",
            "\n",
            "This is NOT for you if: You aren't really adventurous, get scared easily, hate cool and fun things, think the earth is flat, and think technology is evil. \n",
            "\n",
            "How it works:\n",
            "You put on a sorta bulky VR mask that is tethered to the ceiling, take off your shoes (you need to feel the carpet to know when you're walking into the wall*), and you start with a main menu where you use your controller to laser point to the game you want to try out. Yes, the mask is bulky but you get used to it, I was good after a few minutes.\n",
            "* I was half joking about walking into the wall, for starters the wall is really just a soft sheet so you won't get hurt. Also, the VR screen will turn into a grid if you go off your carpet so you also have a visual warning if you're going out of bounds.\n",
            "\n",
            "You are also equipped with a speaker and mic built into the VR mask. I loved how you can hear and talk to your friend the entire time even if you aren't playing the same games. \n",
            "\n",
            "\n",
            "Note: If you choose a multi-player game, it can be tricky to \"find\" your friend and play it simultaneously with them (it would be good to know their username, ask the guide before you start so you can easily find your friend.. I found that a little tricky and wasted quite a bit of time figuring this out).\n",
            "\n",
            "The Birdly is a gimmick.. do not waste your time on it. You lie on your stomach and flap your \"wings\" and the entire thing hurt my neck and felt awkward. I never felt like I was flying. You're  much better off to go in a booth and try VR the old fashioned way and there is a game where you fly and I swear you will feel as if you are zooming in the air (the mind is a powerful thing). I also loved the zombie game (Arizona Sunshine). It was hilarious and not scary at ALL! \n",
            "\n",
            "I also highly recommend you go for 2 hours as the 1st hour I was just warming up and would have really enjoyed a second hour but they were all booked so I had to leave :(\n",
            "\n",
            "One more tip: leave a little bit of a gap between your VR mask and the outside world, that way if you want to know which way you're facing or if you feel disoriented you can always look out of this gap. This really helped me but might be a distraction for others.\n",
            "\n",
            "It's located in the Alexis Nihon shopping center (2nd floor) and they generally validate parking (call to inquire). Definitely reserve first (via phone) at least a day ahead and don't be a jerk and cancel last minute.\n",
            "This place is the worst place in Las Vegas!!!!! Do not and I repeat do not stay at this place. Even if they offer for you to stay there for free because they will. JUST SAY NO!!!!! The problems start with their horrible customer service, there rooms are not secure. The door locks are broken and they even tell you. They just put you in it without making sure their customers will be safe. Then they expect you to have your own working batteries for their TV because the ones in the remote don't work. Ten you have to call twice for maintenance to bring them to you. They won't give them to you when you walk to the desk and ask. Then when you want to take a shower, it makes you feel like your taking a bath because the water doesn't drain. When your shower is done, you will be standing in ankle deep water.  The way they offer to fix it is to move you to another room but you have already moved once before. They are so inconvenient and do not care about their customers or the mistakes that have been made by Tahiti Village. This place is horrible and the managers are not helping at all. I'm extremely mad and Unsatisfied. A birthday has been ruined. THANKS TAHITI VILLAGE FOR NOTHING!!!!!!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "33e150190aa62764e07f1f6c66bb9393",
          "grade": true,
          "grade_id": "cell-203092260fb65165",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWotIpwg7GU9",
        "outputId": "c8a5256b-fcdb-4394-dcc8-864c3fcdef3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Visible Testing\n",
        "assert isinstance(fake_review, str), \"Did you write a review in the correct data type?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brRJKpfW7GU9"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset.\n",
        "\n",
        "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
        "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels).\n",
        "    - Use that pipeline to predict a star rating for your fake review from Part 2.\n",
        "\n",
        "\n",
        "\n",
        "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`.\n",
        "    - Include 2 possible values for each parameter\n",
        "        - **Keep the values for each parameter low. Extreme values will compromise runtime**\n",
        "    - **Use `n_jobs` = 1**\n",
        "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
        "    \n",
        "    \n",
        "3. Train the entire pipeline with a GridSearch\n",
        "    - Name your GridSearch object as `gs`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "jupyter": {
          "outputs_hidden": true
        },
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b3492e82185541e6a463f46b16baff94",
          "grade": false,
          "grade_id": "cell-e2beb0252d274bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "HIYfYW7I7GU9",
        "outputId": "6c2e8107-4a65-4ad9-cf50-5f7965b2e700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                                       ('classifier',\n",
              "                                        RandomForestClassifier())]),\n",
              "             n_jobs=1,\n",
              "             param_grid={'classifier__n_estimators': [50, 100],\n",
              "                         'vectorizer__max_features': [500, 1000]})"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
              "                                       (&#x27;classifier&#x27;,\n",
              "                                        RandomForestClassifier())]),\n",
              "             n_jobs=1,\n",
              "             param_grid={&#x27;classifier__n_estimators&#x27;: [50, 100],\n",
              "                         &#x27;vectorizer__max_features&#x27;: [500, 1000]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
              "                                       (&#x27;classifier&#x27;,\n",
              "                                        RandomForestClassifier())]),\n",
              "             n_jobs=1,\n",
              "             param_grid={&#x27;classifier__n_estimators&#x27;: [50, 100],\n",
              "                         &#x27;vectorizer__max_features&#x27;: [500, 1000]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;classifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "from os import pipe\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipe = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "#Train the model\n",
        "pipe.fit(df.text, df.stars)\n",
        "\n",
        "#predict the star rating\n",
        "prediction = pipe.predict([fake_review])\n",
        "print(prediction)\n",
        "\n",
        "#Create parameter dict\n",
        "param_grid = {\n",
        "    'vectorizer__max_features': [500, 1000],\n",
        "    'classifier__n_estimators': [50, 100]\n",
        "}\n",
        "\n",
        "# Train the pipeline with gridsearch\n",
        "gs = GridSearchCV(pipe, param_grid, cv=5, n_jobs=1)\n",
        "gs.fit(df['text'], df['stars'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ada8e7da1ec21f54451752e97b8cec3e",
          "grade": true,
          "grade_id": "cell-d07134c6fe5d056e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNSKAhAm7GU9",
        "outputId": "23668fd3-9a37-4674-b183-8d7aa1715b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Visible Testing\n",
        "prediction = gs.predict([\"This is your prediction statement.\"])[0]\n",
        "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2990aa9aa4e9c3cf665cee4392cdab92",
          "grade": false,
          "grade_id": "cell-00b8cbd0b1b4ece5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IIzj9zo_7GU9"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Set num_topics to `5`\n",
        "    - Name your LDA model `lda`\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations.\n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "When you instantiate your LDA model, it should look like this:\n",
        "\n",
        "```python\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )\n",
        "\n",
        "```\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9b07079124654b07cce6d10dae1912b6",
          "grade": false,
          "grade_id": "cell-9eee6fe0eeebb9a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1_KfT5ZW7GU9"
      },
      "source": [
        "## Note about  pyLDAvis\n",
        "\n",
        "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
        "\n",
        "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.**\n",
        "\n",
        "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "58830f560044227aa07c22d463e1596c",
          "grade": false,
          "grade_id": "cell-ec7b71ad284832d4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hjcvoio27GU9"
      },
      "source": [
        "### 1. Estimate a LDA topic model of the review text\n",
        "\n",
        "* Use the `tokenize` function you created earlier to create tokens.\n",
        "* Create an `id2word` object.\n",
        "> Hint: Use `corpora.Dictionary`\n",
        "* Create a `corpus` object.\n",
        "> Hint: Use `id2word.doc2bow`\n",
        "* Instantiate an `lda` model.\n",
        "\n",
        ">> Remember to read the LDA docs for more information on the various class attributes and methods available to you in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bef17fce3f84cc31020898134cfdaec1",
          "grade": false,
          "grade_id": "cell-b4df1a20c7947a8b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWX0LXd27GU9",
        "outputId": "8ccf9d39-6471-4e0d-f8d5-e32498853249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Do not change this value\n",
        "num_topics = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = df['text'].apply(tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvNGoPgP-LE_",
        "outputId": "20dd5329-3606-41ab-d8a3-bd098e745022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fb50f495592df233d97bd4199b958404",
          "grade": false,
          "grade_id": "cell-66331a185ff52f15",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWFsUxTK7GU9",
        "outputId": "6470467c-c80c-4890-83aa-c1e0667db29b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "id2word = corpora.Dictionary(tokens)\n",
        "corpus = [id2word.doc2bow(text) for text in tokens]\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               num_topics=num_topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k2kKa8D7GU-"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "073be746ce974f75f29c2c92f35af430",
          "grade": true,
          "grade_id": "cell-5a3c181311134fa9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo06ukQg7GU-",
        "outputId": "39f4f53e-d91a-4080-e4bd-dadf2eb64fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Visible Testing\n",
        "\n",
        "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-ozws9n7GU-"
      },
      "source": [
        "#### 2. Create 2 visualizations of the results:\n",
        "1. Create a visualization using pyLDAvis. Run the cell, then comment out your code before submission, leaving the visualization in the cell.\n",
        "\n",
        "2. Create a visualization using the matplotlib library and utilizing the subplots function. Assign this visualization to a variable called `visual_plot`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "M25lQaQG7GU-",
        "outputId": "6ba9bb34-2386-4fa2-bc19-19866c7056a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "2     -0.100720  0.024403       1        1  33.791114\n",
              "0      0.037605 -0.071245       2        1  32.296520\n",
              "3     -0.006394 -0.054560       3        1  17.414065\n",
              "1     -0.034297  0.041548       4        1  10.227568\n",
              "4      0.103806  0.059854       5        1   6.270732, topic_info=       Term         Freq        Total Category  logprob  loglift\n",
              "103    room  1064.000000  1064.000000  Default  30.0000  30.0000\n",
              "129   place  5337.000000  5337.000000  Default  29.0000  29.0000\n",
              "1725  hotel   471.000000   471.000000  Default  28.0000  28.0000\n",
              "105    stay   614.000000   614.000000  Default  27.0000  27.0000\n",
              "144    food  5348.000000  5348.000000  Default  26.0000  26.0000\n",
              "...     ...          ...          ...      ...      ...      ...\n",
              "78      get    99.408465  2803.044129   Topic5  -5.7395  -0.5699\n",
              "93     nice    86.832239  1830.078963   Topic5  -5.8747  -0.2789\n",
              "0         $    88.271851  2178.984107   Topic5  -5.8583  -0.4369\n",
              "25     look    81.684200  1897.981883   Topic5  -5.9359  -0.3764\n",
              "65    check    76.041731   958.536456   Topic5  -6.0074   0.2352\n",
              "\n",
              "[463 rows x 6 columns], token_table=       Topic      Freq  Term\n",
              "term                        \n",
              "0          1  0.219368     $\n",
              "0          2  0.554387     $\n",
              "0          3  0.139056     $\n",
              "0          4  0.046811     $\n",
              "0          5  0.040386     $\n",
              "...      ...       ...   ...\n",
              "9025       3  0.948802  yuck\n",
              "11618      3  0.978434   yuk\n",
              "3481       2  0.020601     à\n",
              "3481       3  0.020601     à\n",
              "3481       5  0.947647     à\n",
              "\n",
              "[1199 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 4, 2, 5])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1681326994974258087366835518\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1681326994974258087366835518_data = {\"mdsDat\": {\"x\": [-0.10071969980303246, 0.03760518456971764, -0.006393882978078455, -0.03429718209331248, 0.10380558030470582], \"y\": [0.024402728297588057, -0.07124480336877967, -0.054560146726642, 0.04154846813263768, 0.059853753665195866], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [33.791114007752206, 32.29652036070184, 17.414065073304933, 10.227568392327754, 6.270732165913263]}, \"tinfo\": {\"Term\": [\"room\", \"place\", \"hotel\", \"stay\", \"food\", \"time\", \"good\", \"love\", \"wait\", \"great\", \"service\", \"chicken\", \"coffee\", \"go\", \"clean\", \"minute\", \"come\", \"try\", \"look\", \"restaurant\", \"staff\", \"delicious\", \"pool\", \"night\", \"little\", \"nail\", \"burger\", \"drink\", \"noodle\", \"pizza\", \"enchilada\", \"urban\", \"cajun\", \"nigiri\", \"yellowtail\", \"tartar\", \"heartbeat\", \"tikka\", \"biryani\", \"arepa\", \"tamale\", \"jambalaya\", \"dang\", \"pakora\", \"din\", \"brulee\", \"jalape\\u00f1os\", \"scrumptious\", \"quinoa\", \"chimichanga\", \"cola\", \"appliance\", \"coca\", \"accent\", \"horchata\", \"crema\", \"burro\", \"katie\", \"torta\", \"bakersfield\", \"margarita\", \"balsamic\", \"thai\", \"sushi\", \"salsa\", \"gyro\", \"chorizo\", \"salad\", \"chicken\", \"curry\", \"braise\", \"mexican\", \"guacamole\", \"taco\", \"seasoned\", \"roll\", \"fish\", \"rice\", \"tortilla\", \"salmon\", \"food\", \"sauce\", \"indian\", \"fresh\", \"delicious\", \"portion\", \"italian\", \"oyster\", \"japanese\", \"spicy\", \"dish\", \"appetizer\", \"beer\", \"restaurant\", \"shrimp\", \"beef\", \"eat\", \"good\", \"cheese\", \"lunch\", \"great\", \"menu\", \"taste\", \"tasty\", \"order\", \"favorite\", \"fry\", \"place\", \"flavor\", \"little\", \"service\", \"like\", \"try\", \"come\", \"love\", \"nice\", \"price\", \"meal\", \"get\", \"definitely\", \"time\", \"friendly\", \"amazing\", \"go\", \"brake\", \"broken\", \"acrylic\", \"canal\", \"wi\", \"fi\", \"tenant\", \"google\", \"ford\", \"dolphin\", \"johnny\", \"blind\", \"exam\", \"installer\", \"id\", \"physician\", \"terminal\", \"frustration\", \"deposit\", \"grub\", \"nurse\", \"sloppy\", \"library\", \"rule\", \"accomodate\", \"in\", \"explanation\", \"horribly\", \"iphone\", \"froyo\", \"apartment\", \"resolve\", \"loss\", \"dr\", \"office\", \"insurance\", \"practice\", \"rent\", \"dentist\", \"department\", \"phone\", \"company\", \"cat\", \"refund\", \"trade\", \"rude\", \"medical\", \"call\", \"doctor\", \"tell\", \"store\", \"email\", \"help\", \"warranty\", \"sale\", \"say\", \"vet\", \"customer\", \"manager\", \"month\", \"charge\", \"car\", \"$\", \"work\", \"problem\", \"ask\", \"issue\", \"know\", \"want\", \"day\", \"pay\", \"go\", \"people\", \"care\", \"girl\", \"business\", \"time\", \"leave\", \"review\", \"need\", \"year\", \"bad\", \"like\", \"get\", \"take\", \"service\", \"thing\", \"come\", \"find\", \"order\", \"good\", \"look\", \"experience\", \"think\", \"place\", \"great\", \"food\", \"try\", \"yuk\", \"removal\", \"promotion\", \"pedicure\", \"mojito\", \"dunkin\", \"lash\", \"alex\", \"yuck\", \"rv\", \"extension\", \"massage\", \"uneven\", \"van\", \"dont\", \"ikea\", \"facial\", \"desperate\", \"eyebrow\", \"smog\", \"macaron\", \"pamper\", \"michelle\", \"adjustment\", \"rope\", \"danny\", \"cox\", \"installation\", \"sampling\", \"jamba\", \"gel\", \"carnita\", \"polish\", \"manicure\", \"bust\", \"nail\", \"salon\", \"wax\", \"spa\", \"barber\", \"boba\", \"therapist\", \"hair\", \"tow\", \"wait\", \"burger\", \"minute\", \"min\", \"professional\", \"pizza\", \"place\", \"time\", \"look\", \"cut\", \"come\", \"wash\", \"long\", \"service\", \"amazing\", \"feel\", \"recommend\", \"good\", \"take\", \"friendly\", \"go\", \"great\", \"get\", \"new\", \"need\", \"order\", \"love\", \"try\", \"staff\", \"food\", \"drink\", \"like\", \"price\", \"$\", \"contractor\", \"trail\", \"eclectic\", \"ami\", \"thrill\", \"chai\", \"museum\", \"nancy\", \"reuben\", \"pt\", \"gabi\", \"dedicated\", \"yoga\", \"arcade\", \"mighty\", \"a.m.\", \"hiking\", \"mic\", \"passionate\", \"nite\", \"l\", \"corned\", \"lentil\", \"bikini\", \"scott\", \"und\", \"tai\", \"exhibit\", \"cobbler\", \"gallery\", \"keg\", \"instructor\", \"donut\", \"latte\", \"vietnamese\", \"class\", \"pho\", \"guide\", \"cupcake\", \"bagel\", \"raman\", \"mocha\", \"gym\", \"broth\", \"gluten\", \"cookie\", \"pastry\", \"slider\", \"coast\", \"coffee\", \"noodle\", \"workout\", \"chocolate\", \"tea\", \"park\", \"love\", \"milk\", \"play\", \"art\", \"try\", \"enjoy\", \"area\", \"good\", \"like\", \"stop\", \"place\", \"great\", \"little\", \"time\", \"find\", \"sweet\", \"come\", \"friend\", \"old\", \"big\", \"know\", \"definitely\", \"recommend\", \"experience\", \"go\", \"order\", \"delicious\", \"work\", \"want\", \"taste\", \"get\", \"food\", \"cirque\", \"des\", \"curly\", \"stunning\", \"pastor\", \"une\", \"mais\", \"j'ai\", \"bouchon\", \"\\u00e0\", \"je\", \"unorganized\", \"disgust\", \"dans\", \"humor\", \"cabinet\", \"avec\", \"vous\", \"sur\", \"festival\", \"tr\\u00e8s\", \"tile\", \"les\", \"que\", \"verify\", \"gumbo\", \"et\", \"comme\", \"luxurious\", \"howard\", \"est\", \"en\", \"sont\", \"pas\", \"roof\", \"de\", \"le\", \"un\", \"hotel\", \"bed\", \"suite\", \"room\", \"la\", \"motel\", \"shower\", \"casino\", \"tan\", \"stay\", \"lobby\", \"pool\", \"pour\", \"floor\", \"bathroom\", \"strip\", \"clean\", \"guest\", \"night\", \"staff\", \"service\", \"go\", \"drink\", \"comfortable\", \"place\", \"restaurant\", \"great\", \"time\", \"experience\", \"good\", \"like\", \"food\", \"come\", \"get\", \"nice\", \"$\", \"look\", \"check\"], \"Freq\": [1064.0, 5337.0, 471.0, 614.0, 5348.0, 4177.0, 6582.0, 2267.0, 1582.0, 4470.0, 3799.0, 1586.0, 635.0, 3014.0, 841.0, 986.0, 3887.0, 2604.0, 1897.0, 1810.0, 1605.0, 1364.0, 244.0, 1061.0, 1498.0, 346.0, 698.0, 1424.0, 327.0, 849.0, 77.76264486248236, 25.16802482156413, 38.1337546740017, 42.80599196155473, 35.66779679414862, 18.987087286887814, 19.72757700201764, 28.48969751329088, 15.277696389162635, 21.586111388973602, 47.23170107878206, 15.150867229545645, 15.297687223040906, 20.490516264848797, 19.737609378430214, 31.346798106418866, 13.560458675048654, 13.527214537531743, 15.177707077976864, 20.35008480722104, 13.323174008440194, 17.151166038745117, 12.885496288643294, 13.371304937143051, 14.690938694953763, 14.782182546474171, 13.527026710699523, 13.699147584387815, 16.573575505734592, 13.31793545750028, 120.6544991338679, 29.864517217979834, 241.056539616656, 563.8321666554035, 224.45891015853712, 63.833988642339996, 41.850430829244985, 724.3810170927655, 1315.6932720493394, 163.54494773347682, 22.394602899869138, 223.79370749669113, 99.77095704027795, 420.3596108461056, 57.65739414873901, 515.3614628484177, 365.8920204114428, 473.5031166329271, 82.93036933343154, 210.71969971672982, 3716.8564496136387, 774.1327241312115, 96.92003170867895, 781.6944239691909, 1002.7378425392004, 439.56531402426526, 165.2161072843962, 97.31575254951596, 108.38850057396843, 322.8508741030928, 697.981299036236, 289.7751263707315, 496.54663336703777, 1187.4290766570366, 303.6739435720572, 385.43876864547326, 1059.4645510989317, 3573.838245699695, 642.8609727942426, 565.3834854166505, 2430.688876989103, 880.5660031239272, 810.9084326425344, 411.53350439791814, 1879.7261880230194, 476.1517900315917, 630.8915128134798, 2351.8004829193155, 532.4648239288978, 824.8347040678007, 1540.0311974922065, 1552.2830714743232, 1148.135257419376, 1420.1984734675232, 1000.4348674547017, 861.9033351887937, 837.2407560080914, 587.8022246703529, 949.2192453566498, 703.2629023096671, 858.4239388530148, 648.8838013369142, 638.2189210963063, 663.4734335092846, 40.64595465499994, 35.407932410480015, 30.10256383476248, 34.415541112515925, 23.785313968967735, 22.867591068408718, 26.402548430430123, 22.349121142725966, 41.39503839513451, 20.77726277594688, 19.23807110916485, 20.77448080773582, 23.496371477144812, 16.95176693867423, 19.911961792610583, 22.13842585004508, 22.070495791962212, 16.4559673900786, 29.996452942355806, 22.89425951138451, 46.252883025492636, 17.879396981646817, 35.09611570043544, 29.32104155771893, 15.260282780631327, 19.505085622578118, 17.16146503125948, 17.070996629551622, 22.884685927191082, 13.081875428851067, 79.45718158560577, 32.32401293701218, 30.53088038594529, 86.3489484235735, 286.18470658282166, 92.95265067642275, 62.564069933393185, 90.76324864344865, 62.22687036934629, 52.977421376341965, 312.96333495733415, 325.6976241897833, 64.63564715785459, 74.20746627236858, 37.61398224156642, 271.6151058990932, 45.638019406941424, 594.0105222404665, 122.86529016683787, 1059.2345121796598, 593.0361616174023, 108.08657627559764, 434.70589595168684, 63.35030372029626, 117.55682227932483, 961.6257408392638, 71.02320368405073, 705.0815180357383, 326.5517556054979, 313.91397588474365, 323.3409983024439, 430.13433229652003, 1207.5953526996968, 830.3046849332412, 263.947621623663, 806.8973480207329, 239.24083454053613, 888.3067532137784, 928.5265362822612, 828.5967927220568, 480.42505339567816, 1379.5337930726134, 758.6689062106497, 380.44875993275144, 223.29521354365386, 320.76051778736354, 1653.1349972695032, 547.5238102699001, 501.9051650362453, 670.0273658124983, 508.7363632607386, 601.2595947907508, 1286.1452003334753, 1042.7016619362146, 639.9473820161382, 1120.3291840292711, 556.9416413055341, 1069.736036810516, 648.6127057071282, 939.4163968054137, 1186.158974247993, 683.4212108322447, 587.4245634318277, 568.4735643404387, 782.8080698581532, 731.7958993908487, 729.58552025203, 584.7705518602179, 48.18533277395312, 20.22053057664681, 20.034249771182203, 124.96936478853674, 14.954604128244455, 18.06490169046965, 35.26817581414777, 18.098957479205616, 14.889112899353885, 11.762149020889545, 21.815628432854368, 147.17708130025218, 13.079774693667222, 11.181857964749417, 10.302074679581818, 16.86997028043692, 51.59400410850673, 12.40186378761316, 52.122230412043066, 12.132197695047685, 15.762143603680137, 15.028304866775306, 9.87455069511995, 14.9919784423287, 11.995110249723307, 9.75728884712936, 21.694248091323715, 21.940983011365905, 9.716366820869059, 8.841952252754362, 85.03104586229988, 19.538369410238893, 73.98461545571342, 54.65434144022518, 14.855057110617917, 280.46732429070056, 171.8173106145671, 46.37645294192201, 80.98558236144228, 44.3897890782104, 48.55544389683817, 29.967810141826188, 233.64996335316417, 23.785408658757174, 766.3366447278835, 359.6499919225067, 479.8246433764528, 124.03475214562481, 182.34077040247442, 379.963074010391, 1611.4623602474696, 1184.2148288058088, 631.0007213288395, 198.61097186884632, 989.962398387388, 57.811719097671784, 316.0581027342453, 874.177382853973, 415.88761841775613, 353.6474003078193, 403.87320276859424, 1131.5894764784493, 400.0599735933891, 401.30810882080453, 619.565270324858, 781.4093094233358, 563.6435044944478, 319.4263972199246, 350.20286841632185, 586.3281194520735, 447.349746660294, 471.68988236434126, 373.67096010592815, 637.9074905748894, 349.9637847143013, 501.6353358619318, 311.379703900458, 303.1734016267924, 25.027233262831874, 35.76920761000026, 18.34378730285921, 18.15987916982741, 14.568377326529157, 31.390282136324316, 42.408206708248464, 11.956205803879689, 13.682378666902453, 14.560384637637064, 12.662401239343916, 11.08969885949167, 32.0495234587211, 11.225010475782254, 12.78921915659985, 11.518149823042458, 10.109428136203416, 11.011696788453708, 11.050947228728868, 9.848105500397475, 18.25036321536866, 15.843671870073559, 8.8005585776737, 9.99348573340363, 12.29885419587136, 8.011978882896788, 11.090678139931368, 24.291876543023275, 9.55854657847522, 13.721505871886324, 24.994570042293407, 41.67811096170841, 137.60983123780923, 52.06205744594977, 28.24032353918938, 155.48738715781715, 83.54343980427177, 38.712412598437524, 49.91445949806642, 56.96074829984714, 104.52392538692033, 34.758666484746044, 82.29382808226647, 90.77769176700238, 45.9104040437935, 96.42425652529487, 55.7393046444219, 53.023057984106295, 31.206086454279514, 261.2559537766608, 151.88401071395126, 33.72649169752361, 125.90480243096287, 139.35596968510742, 89.54639515662133, 417.92044922677565, 63.82531199375602, 93.56364852375644, 51.12298692129526, 357.6173368300101, 199.2541191780069, 184.6037199626049, 553.5482344596787, 384.81153945484635, 152.0562114943107, 431.9876286236374, 393.70992558104393, 221.24173637618404, 352.44725252296104, 219.158613959033, 143.83381201925704, 296.69645178636614, 157.92738724184318, 120.85656848526138, 135.8096687861494, 173.91339880752773, 165.36420281336768, 161.53774701888207, 151.72788920493124, 183.07953414326323, 183.59458724067972, 146.9099526769106, 147.09319768670832, 150.79277981463954, 144.62210709919455, 148.07125164184018, 144.0162706705294, 26.60649953943488, 28.71706718889682, 17.574525055547216, 15.918284586780711, 22.81910723943408, 25.78093748600603, 20.085118806993115, 15.744299497848022, 14.385450263534056, 45.67243509638902, 17.920455165056552, 14.64770608790925, 13.293443409392227, 12.397891180132804, 12.130936362330814, 15.192995311155343, 14.383554115344223, 21.284653814317547, 11.532420064613596, 13.100581391658864, 20.741885892483268, 24.388155474503623, 37.92788586632888, 24.49688356207201, 11.048865396663789, 9.343118189722716, 55.71490724828482, 10.681314880185381, 9.991464146487436, 8.580128127057293, 25.124472632864922, 35.44066834787983, 15.384731153588103, 20.513182356357092, 38.71753983828804, 112.35576086593078, 59.136515651847446, 43.62455547332451, 301.1063752310965, 105.46269730923827, 52.848532051952425, 572.2501261948215, 115.80445504477434, 21.541369611794654, 64.13936052955563, 104.43684156049332, 31.7857473648681, 241.6239690477854, 52.15444466836164, 112.81018879074256, 46.891845478667214, 96.45611573967649, 67.2203674677629, 89.06391545853869, 131.47502963847862, 56.723359450930666, 122.87813121405357, 139.59525008039563, 190.6125743195145, 168.90801722925713, 107.1904517085951, 58.910546598879286, 159.00340260657086, 112.28539829667012, 132.67159629237494, 129.39585817327566, 95.84469969756155, 137.03593215667894, 119.93893601162249, 120.01499062345678, 110.91779691724844, 99.40846524529927, 86.83223898921005, 88.27185082379549, 81.68420025181972, 76.04173097941921], \"Total\": [1064.0, 5337.0, 471.0, 614.0, 5348.0, 4177.0, 6582.0, 2267.0, 1582.0, 4470.0, 3799.0, 1586.0, 635.0, 3014.0, 841.0, 986.0, 3887.0, 2604.0, 1897.0, 1810.0, 1605.0, 1364.0, 244.0, 1061.0, 1498.0, 346.0, 698.0, 1424.0, 327.0, 849.0, 79.80873175166536, 25.952947454391843, 39.61875062895256, 44.53300937782662, 37.130689094144564, 19.789447006615738, 20.63298379781601, 29.833829677048037, 16.01664800107908, 22.688024658259653, 49.657247499101615, 15.929271058936328, 16.093694607986766, 21.58917765414746, 20.805830004155595, 33.068711109172405, 14.311659936778616, 14.291469728179159, 16.035496367813973, 21.51343388974882, 14.08768980547396, 18.157973086624665, 13.644740709793176, 14.16035368926372, 15.558295756789114, 15.6626578290141, 14.355095120048855, 14.54612259924934, 17.61634435736594, 14.156664962523838, 128.84866147252671, 31.84263195101867, 262.5347242893708, 627.6567403946227, 248.8491112178539, 69.13230548504036, 44.98531614844374, 855.3936348883332, 1586.9305826358589, 185.38758988710185, 23.976155443524647, 259.1177687221635, 112.4885023406654, 505.36068917615285, 64.082449547026, 634.951838848726, 443.66450108404314, 586.558790817714, 93.87661769078733, 251.37824644658699, 5348.380721734544, 1009.9747688435218, 111.16512450409417, 1028.6813342462415, 1364.0767592084994, 563.1504861711893, 197.08496491627673, 111.97768582027291, 125.97478159878953, 416.17770504506825, 972.666802805766, 370.5619693856841, 679.9088527368999, 1810.443455983762, 396.90524825115796, 521.4092729831688, 1637.0439461486662, 6582.170863042495, 938.38313383459, 816.4227946566331, 4470.2756076767055, 1373.550901483823, 1278.2755823219363, 569.2694155762932, 3634.391472687692, 681.1495021791973, 973.0947889762336, 5337.061944255146, 807.4711974233342, 1498.0329887602834, 3799.1025694337663, 3844.814083136199, 2604.6780155701026, 3887.5111573690415, 2267.3848084788915, 1830.0789632282494, 1820.675334510222, 957.0983125584444, 2803.0441286744517, 1448.9642571932181, 4177.616875624563, 1443.760175443109, 1393.6089494851426, 3014.560048279276, 41.54303240443427, 36.22098788804164, 31.03092229210197, 35.47954955076851, 24.579454609281992, 23.663058727794404, 27.34337404252649, 23.18829931792442, 43.006698644328694, 21.66514708981091, 20.109525688382877, 21.717144785962837, 24.579467186800997, 17.737116842104992, 20.857936420227997, 23.207256521591976, 23.144649410353008, 17.263222298514222, 31.496923003059155, 24.10426905462415, 48.712400147589136, 18.830494248302827, 37.03431682201569, 30.952169411182084, 16.1221809168955, 20.62222247244493, 18.15299236881404, 18.06391228546817, 24.241709078601538, 13.869085638841806, 84.24171500658315, 34.3973703412424, 32.47575846128621, 93.77985257464165, 321.69378558554206, 101.88877785944702, 67.77300714774687, 100.13184260437728, 68.01486421425639, 57.65510820157886, 369.26687039252033, 387.9189144461552, 71.10264025100989, 82.27823217722313, 40.46989402599768, 327.3653235676362, 49.637570071505486, 778.4982394546395, 143.35675140491952, 1481.9753389082161, 805.5524880253972, 127.04657360483904, 591.6630754390989, 71.36650979822797, 140.99905911520239, 1475.8797557932605, 81.65873582399107, 1087.7040918391579, 454.85709512845773, 440.3495529598172, 461.92503384821583, 648.1668378788114, 2178.9841072343584, 1428.5764075513691, 378.82611191035386, 1433.3876651351538, 342.1013694283002, 1648.9522569848036, 1749.7551910536752, 1533.2528291353378, 802.6772152699045, 3014.560048279276, 1449.4919275714442, 619.3214665670506, 315.9605246044671, 503.42621285052934, 4177.616875624563, 1000.9923784129879, 911.1262450376355, 1336.6680774480656, 947.2151475768076, 1212.1518844546192, 3844.814083136199, 2803.0441286744517, 1397.631351224799, 3799.1025694337663, 1185.7999410601903, 3887.5111573690415, 1568.1805287097434, 3634.391472687692, 6582.170863042495, 1897.9818828952132, 1404.995148156415, 1462.7892654635534, 5337.061944255146, 4470.2756076767055, 5348.380721734544, 2604.6780155701026, 49.057994519409576, 21.035732464929616, 20.879883693458257, 131.2990287835107, 15.796632847669159, 19.10120000548715, 37.29441701016731, 19.142459067669556, 15.809416263151403, 12.59891924676415, 23.392303722638037, 157.81719864119586, 14.088330723953858, 12.052477867256474, 11.11223719305387, 18.206927381704816, 55.71177352225811, 13.40514692964093, 56.37667603028503, 13.122763364106225, 17.10070257031734, 16.305978760148953, 10.748336615882192, 16.37954794466549, 13.127469459633998, 10.684435105540729, 23.762954752472734, 24.06236052212693, 10.675359003323425, 9.719694286303145, 93.84566705255499, 21.494967344560223, 83.11890556214848, 61.95526300253148, 16.35788195932466, 346.3629607421608, 213.27211299285122, 53.74420831348273, 99.43955344596733, 52.339328378031105, 58.71395626406423, 35.320713897204215, 367.4041325099917, 27.591730725246617, 1582.349624243693, 698.8127278322374, 986.6939052197265, 208.86589423711004, 339.32759193777525, 849.5501872525804, 5337.061944255146, 4177.616875624563, 1897.9818828952132, 435.676242791388, 3887.5111573690415, 86.22830921125009, 862.1766688296657, 3799.1025694337663, 1393.6089494851426, 1119.5974435550866, 1399.1666925441154, 6582.170863042495, 1397.631351224799, 1443.760175443109, 3014.560048279276, 4470.2756076767055, 2803.0441286744517, 1099.3890961768113, 1336.6680774480656, 3634.391472687692, 2267.3848084788915, 2604.6780155701026, 1605.7016588514862, 5348.380721734544, 1424.9839577036523, 3844.814083136199, 1820.675334510222, 2178.9841072343584, 26.00809056329344, 37.56940523304486, 19.27055941132115, 19.19318607602729, 15.44044401529544, 33.39649849822392, 45.12012573928637, 12.751831457829596, 14.616976849601896, 15.570484301697128, 13.559093763330072, 11.885230844912009, 34.364373488854184, 12.06427394576762, 13.766116973516699, 12.424079675144437, 10.93925609127453, 11.92893280880416, 11.97281798569969, 10.705310842616548, 19.858910173372397, 17.244970157838097, 9.588887343397097, 10.907106625100708, 13.428342066472094, 8.808061922115535, 12.217649582716456, 26.76504948576687, 10.536998100815211, 15.155250264211471, 28.272438449482387, 49.280080422941936, 175.25749397098232, 63.872333951116985, 33.65140897442587, 214.96634697229715, 112.66155883975712, 48.442336283673015, 64.48423349027155, 75.04040596011339, 159.40783257593037, 44.571818320138746, 124.78189371910787, 141.34443375838802, 62.93631521060183, 154.5653406541331, 82.41688613711436, 78.35040313741742, 41.03287886946499, 635.9294604538517, 327.9926646113993, 47.22907005634371, 316.14837577515976, 370.1546940247424, 198.3543108422163, 2267.3848084788915, 127.0058124803893, 235.51186634726807, 89.58521412726267, 2604.6780155701026, 938.6773970255523, 834.975363333248, 6582.170863042495, 3844.814083136199, 672.1905043661764, 5337.061944255146, 4470.2756076767055, 1498.0329887602834, 4177.616875624563, 1568.1805287097434, 671.7088380813368, 3887.5111573690415, 1043.7847530765923, 575.3133437501014, 807.7874983540455, 1648.9522569848036, 1448.9642571932181, 1399.1666925441154, 1404.995148156415, 3014.560048279276, 3634.391472687692, 1364.0767592084994, 1428.5764075513691, 1749.7551910536752, 1278.2755823219363, 2803.0441286744517, 5348.380721734544, 27.41008979428789, 29.988033967050555, 18.396512814205757, 16.74068606705886, 24.064801355780695, 27.2322128107126, 21.249423561529714, 16.698467746867376, 15.282881829716809, 48.541257370290296, 19.065471204358513, 15.599135079371184, 14.159546992050347, 13.232246315691754, 12.960935906722925, 16.24052911969804, 15.380676865823455, 22.77460402958614, 12.363384378356562, 14.048130940521236, 22.29113310542012, 26.259546736121155, 40.96404792315901, 26.603082390765863, 12.032377857913641, 10.178343424011263, 60.714339993922856, 11.640142781895321, 10.888905979627804, 9.394197296193825, 27.541922000423984, 39.19133764181237, 16.85847196831946, 22.75740374637851, 43.82311681415769, 134.52965632733654, 68.69005060207954, 52.66674246857634, 471.31655048969026, 145.92673349068406, 68.4545908733439, 1064.3087188689985, 182.36527484994602, 24.743768870968857, 92.98540065686468, 170.98024185596586, 41.51626735030403, 614.7430785610529, 83.30071160062735, 244.7850010285963, 82.05602049516357, 254.79726690429493, 168.9828725937333, 370.0794955916984, 841.439127979991, 166.26036593643585, 1061.4770710016269, 1605.7016588514862, 3799.1025694337663, 3014.560048279276, 1424.9839577036523, 248.3296100543832, 5337.061944255146, 1810.443455983762, 4470.2756076767055, 4177.616875624563, 1404.995148156415, 6582.170863042495, 3844.814083136199, 5348.380721734544, 3887.5111573690415, 2803.0441286744517, 1830.0789632282494, 2178.9841072343584, 1897.9818828952132, 958.5364557515593], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.6694, -8.7975, -8.3819, -8.2664, -8.4488, -9.0793, -9.041, -8.6735, -9.2966, -8.951, -8.168, -9.305, -9.2953, -9.0031, -9.0405, -8.5779, -9.4159, -9.4183, -9.3032, -9.0099, -9.4335, -9.181, -9.4669, -9.4299, -9.3358, -9.3296, -9.4183, -9.4057, -9.2152, -9.4339, -7.2301, -8.6264, -6.538, -5.6883, -6.6093, -7.8667, -8.2889, -5.4377, -4.8409, -6.9259, -8.9142, -6.6123, -7.4202, -5.9819, -7.9685, -5.7782, -6.1207, -5.8629, -7.605, -6.6725, -3.8024, -5.3713, -7.4491, -5.3616, -5.1125, -5.9372, -6.9158, -7.4451, -7.3373, -6.2458, -5.4748, -6.3539, -5.8154, -4.9435, -6.3071, -6.0686, -5.0575, -3.8416, -5.5571, -5.6855, -4.2271, -5.2425, -5.3249, -6.0031, -4.4841, -5.8573, -5.5759, -4.2601, -5.7455, -5.3078, -4.6835, -4.6755, -4.9771, -4.7645, -5.1148, -5.2639, -5.2929, -5.6466, -5.1674, -5.4673, -5.2679, -5.5478, -5.5643, -5.5255, -8.2729, -8.4109, -8.5732, -8.4393, -8.8087, -8.8481, -8.7043, -8.871, -8.2546, -8.9439, -9.0209, -8.9441, -8.8209, -9.1474, -8.9865, -8.8805, -8.8836, -9.1771, -8.5767, -8.8469, -8.1437, -9.0941, -8.4197, -8.5995, -9.2525, -9.0071, -9.1351, -9.1404, -8.8473, -9.4066, -7.6026, -8.502, -8.5591, -7.5194, -6.3212, -7.4457, -7.8416, -7.4695, -7.847, -8.0079, -6.2317, -6.1918, -7.809, -7.6709, -8.3504, -6.3734, -8.1571, -5.5909, -7.1667, -5.0125, -5.5925, -7.2949, -5.9031, -7.8291, -7.2109, -5.1092, -7.7148, -5.4195, -6.1892, -6.2287, -6.1991, -5.9137, -4.8814, -5.256, -6.402, -5.2846, -6.5003, -5.1885, -5.1442, -5.2581, -5.8031, -4.7483, -5.3462, -6.0364, -6.5693, -6.2071, -4.5674, -5.6724, -5.7594, -5.4705, -5.7459, -5.5788, -4.8184, -5.0282, -5.5164, -4.9564, -5.6553, -5.0026, -5.503, -5.1325, -4.8993, -5.4507, -5.602, -5.6348, -5.3149, -5.3823, -5.3853, -5.6066, -7.4851, -8.3534, -8.3627, -6.532, -8.6551, -8.4661, -7.7971, -8.4643, -8.6595, -8.8952, -8.2775, -6.3685, -8.789, -8.9458, -9.0278, -8.5346, -7.4167, -8.8423, -7.4065, -8.8642, -8.6025, -8.6502, -9.0701, -8.6526, -8.8756, -9.0821, -8.2831, -8.2718, -9.0863, -9.1806, -6.9171, -8.3877, -7.0563, -7.3591, -8.6618, -5.7237, -6.2137, -7.5233, -6.9658, -7.5671, -7.4774, -7.96, -5.9063, -8.191, -4.7185, -5.475, -5.1867, -6.5395, -6.1542, -5.42, -3.9752, -4.2833, -4.9128, -6.0688, -4.4624, -7.3029, -5.6042, -4.5868, -5.3297, -5.4918, -5.359, -4.3287, -5.3685, -5.3654, -4.9311, -4.699, -5.0257, -5.5936, -5.5016, -4.9862, -5.2568, -5.2038, -5.4367, -4.9019, -5.5023, -5.1422, -5.6191, -5.6458, -7.608, -7.2508, -7.9186, -7.9287, -8.1491, -7.3814, -7.0806, -8.3467, -8.2118, -8.1496, -8.2893, -8.4219, -7.3606, -8.4098, -8.2793, -8.384, -8.5145, -8.429, -8.4254, -8.5406, -7.9237, -8.0651, -8.6531, -8.526, -8.3184, -8.747, -8.4218, -7.6378, -8.5705, -8.209, -7.6093, -7.0979, -5.9035, -6.8755, -7.4872, -5.7814, -6.4026, -7.1718, -6.9176, -6.7856, -6.1785, -7.2795, -6.4176, -6.3195, -7.0012, -6.2592, -6.8072, -6.8572, -7.3873, -5.2624, -5.8048, -7.3096, -5.9924, -5.8909, -6.3332, -4.7926, -6.6718, -6.2893, -6.8937, -4.9485, -5.5333, -5.6097, -4.5116, -4.8752, -5.8037, -4.7595, -4.8523, -5.4287, -4.963, -5.4381, -5.8593, -5.1352, -5.7658, -6.0333, -5.9167, -5.6694, -5.7198, -5.7432, -5.8058, -5.618, -5.6152, -5.8381, -5.8369, -5.812, -5.8538, -5.8302, -5.858, -7.0576, -6.9812, -7.4723, -7.5713, -7.2111, -7.0891, -7.3387, -7.5822, -7.6725, -6.5172, -7.4528, -7.6544, -7.7515, -7.8212, -7.843, -7.6179, -7.6726, -7.2807, -7.8936, -7.7661, -7.3066, -7.1446, -6.703, -7.1402, -7.9364, -8.1041, -6.3185, -7.9702, -8.037, -8.1893, -7.1149, -6.7709, -7.6054, -7.3177, -6.6824, -5.6171, -6.2589, -6.5631, -4.6313, -5.6804, -6.3713, -3.9891, -5.5868, -7.2688, -6.1777, -5.6901, -6.8797, -4.8513, -6.3845, -5.613, -6.4909, -5.7696, -6.1307, -5.8494, -5.4599, -6.3005, -5.5275, -5.4, -5.0885, -5.2094, -5.6641, -6.2627, -5.2698, -5.6177, -5.4508, -5.4758, -5.776, -5.4185, -5.5517, -5.5511, -5.6299, -5.7395, -5.8747, -5.8583, -5.9359, -6.0074], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.059, 1.0543, 1.0468, 1.0454, 1.0448, 1.0436, 1.0401, 1.0389, 1.0377, 1.0352, 1.0349, 1.0349, 1.0342, 1.0327, 1.0323, 1.0315, 1.0311, 1.03, 1.03, 1.0294, 1.0292, 1.0279, 1.0277, 1.0276, 1.0276, 1.0271, 1.0256, 1.025, 1.024, 1.0239, 1.0193, 1.0208, 0.9996, 0.9777, 0.9818, 1.0052, 1.0127, 0.9187, 0.8975, 0.9596, 1.0167, 0.9384, 0.965, 0.9008, 0.9793, 0.8763, 0.8922, 0.8709, 0.961, 0.9085, 0.7211, 0.819, 0.9478, 0.8104, 0.7772, 0.8372, 0.9086, 0.9446, 0.9346, 0.8311, 0.7531, 0.8391, 0.7707, 0.6632, 0.8172, 0.7828, 0.6498, 0.4742, 0.7067, 0.7175, 0.4757, 0.6404, 0.6299, 0.7605, 0.4257, 0.7269, 0.6516, 0.2655, 0.6686, 0.4882, 0.182, 0.178, 0.2658, 0.078, 0.2668, 0.332, 0.3081, 0.5975, 0.0022, 0.3621, -0.4974, 0.2852, 0.304, -0.4287, 1.1084, 1.1075, 1.0998, 1.0998, 1.0974, 1.096, 1.0952, 1.0933, 1.092, 1.0884, 1.0859, 1.0858, 1.0851, 1.0849, 1.0838, 1.0831, 1.0827, 1.0823, 1.0814, 1.0787, 1.0784, 1.0784, 1.0765, 1.0761, 1.0753, 1.0745, 1.074, 1.0737, 1.0726, 1.0718, 1.0717, 1.068, 1.0685, 1.0477, 1.0132, 1.0384, 1.0502, 1.032, 1.0413, 1.0456, 0.9648, 0.9554, 1.0349, 1.027, 1.057, 0.9435, 1.0462, 0.8597, 0.976, 0.7944, 0.8239, 0.9686, 0.8219, 1.0111, 0.9484, 0.7018, 0.9907, 0.6967, 0.7988, 0.7918, 0.7735, 0.7202, 0.54, 0.5876, 0.7689, 0.5556, 0.7726, 0.5116, 0.4966, 0.5148, 0.6169, 0.3485, 0.4828, 0.6429, 0.7831, 0.6795, 0.2031, 0.5269, 0.5339, 0.4396, 0.5086, 0.4291, 0.0351, 0.1413, 0.3491, -0.0909, 0.3745, -0.1601, 0.2474, -0.2227, -0.5834, 0.1088, 0.2582, 0.1851, -0.7893, -0.6795, -0.8619, -0.3636, 1.7299, 1.7084, 1.7065, 1.6985, 1.6931, 1.6921, 1.692, 1.6918, 1.6879, 1.6792, 1.6781, 1.6781, 1.6736, 1.6729, 1.6722, 1.6716, 1.6711, 1.6701, 1.6694, 1.6694, 1.6664, 1.6663, 1.6631, 1.6594, 1.6577, 1.6571, 1.6568, 1.6556, 1.6538, 1.6532, 1.6493, 1.6525, 1.6315, 1.6225, 1.6515, 1.5369, 1.5318, 1.6004, 1.5426, 1.5832, 1.5579, 1.5835, 1.2953, 1.5994, 1.0228, 1.0836, 1.027, 1.2268, 1.1268, 0.9433, 0.5504, 0.4872, 0.6467, 0.9623, 0.38, 1.3481, 0.7444, 0.2787, 0.5387, 0.5955, 0.5054, -0.0128, 0.497, 0.4676, 0.1657, 0.0038, 0.1439, 0.5119, 0.4085, -0.0764, 0.1249, 0.0391, 0.29, -0.3785, 0.3438, -0.2887, -0.0181, -0.2244, 2.2416, 2.231, 2.2308, 2.2247, 2.2219, 2.2181, 2.2181, 2.2157, 2.214, 2.213, 2.2117, 2.2108, 2.2103, 2.208, 2.2065, 2.2044, 2.2012, 2.2001, 2.2, 2.1966, 2.1956, 2.1953, 2.1943, 2.1926, 2.1922, 2.1854, 2.1833, 2.1831, 2.1826, 2.1807, 2.1569, 2.1125, 2.0382, 2.0756, 2.1048, 1.9562, 1.9811, 2.0559, 2.024, 2.0044, 1.858, 2.0314, 1.8638, 1.8373, 1.9647, 1.8082, 1.889, 1.8896, 2.0063, 1.3905, 1.5102, 1.9434, 1.3594, 1.3032, 1.4848, 0.589, 1.592, 1.357, 1.7191, 0.2945, 0.7302, 0.7709, -0.1957, -0.0216, 0.7938, -0.234, -0.1495, 0.3674, -0.1925, 0.3122, 0.7389, -0.2927, 0.3916, 0.7198, 0.497, 0.0307, 0.1096, 0.1212, 0.0544, -0.5212, -0.7054, 0.0517, 0.0067, -0.1712, 0.1009, -0.6607, -1.3345, 2.7395, 2.726, 2.7236, 2.7189, 2.7161, 2.7145, 2.7129, 2.7104, 2.7088, 2.7084, 2.7073, 2.7063, 2.7062, 2.7041, 2.7031, 2.7026, 2.7023, 2.7016, 2.6997, 2.6994, 2.6972, 2.6953, 2.6923, 2.6868, 2.684, 2.6837, 2.6833, 2.6833, 2.6833, 2.6786, 2.6774, 2.6687, 2.6778, 2.6655, 2.6454, 2.5892, 2.6195, 2.5809, 2.3212, 2.4445, 2.5105, 2.1488, 2.3152, 2.6307, 2.3979, 2.2763, 2.5022, 1.8355, 2.301, 1.9946, 2.2097, 1.7979, 1.8475, 1.3449, 0.913, 1.6939, 0.6131, 0.3267, -0.223, -0.1126, 0.182, 1.3305, -0.7442, -0.011, -0.7481, -0.7053, 0.0842, -1.1026, -0.6982, -1.0277, -0.7875, -0.5699, -0.2789, -0.4369, -0.3764, 0.2352]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 4, 1, 2, 2, 3, 5, 3, 1, 2, 3, 4, 5, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 1, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 1, 2, 3, 4, 5, 5, 1, 4, 2, 2, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 1, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 3, 4, 2, 3, 1, 1, 2, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 5, 3, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 1, 2, 3, 4, 5, 2, 3, 5, 2, 3, 5, 2, 4, 5, 1, 2, 3, 4, 5, 2, 2, 3, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 4, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 4, 1, 2, 1, 2, 3, 4, 5, 5, 5, 2, 3, 4, 2, 4, 1, 2, 3, 4, 5, 3, 4, 2, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 3, 1, 1, 2, 3, 4, 5, 5, 2, 1, 2, 4, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 2, 3, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 1, 2, 3, 4, 5, 2, 5, 2, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 2, 5, 4, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 3, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 2, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 1, 2, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 3, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 3, 2, 3, 4, 2, 4, 1, 2, 3, 4, 5, 2, 3, 5, 2, 3, 4, 5, 4, 2, 5, 3, 5, 1, 3, 5, 2, 3, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 3, 3, 2, 3, 5], \"Freq\": [0.21936828194983674, 0.5543867878564912, 0.13905562642426889, 0.046810804934902396, 0.040385792492856974, 0.9658663107261901, 0.9180561647875015, 0.9303952162129945, 0.9667775813300798, 0.9157761893474733, 0.06105174595649822, 0.9403180613509003, 0.45780417830676523, 0.11122201824067181, 0.29850554572980303, 0.09400054444856779, 0.03874831603223405, 0.9378328292498761, 0.011870603535574436, 0.9377776793103805, 0.011870603535574436, 0.023741207071148872, 0.7825951499576728, 0.11603997051096528, 0.051273475342054425, 0.03778045551519799, 0.013493019826856427, 0.9362278443138767, 0.9117830090271625, 0.38324484056936714, 0.20359882155247627, 0.13533333432605776, 0.22156342345416535, 0.05748672608540507, 0.9696745455533002, 0.14511323243066096, 0.13395067608984088, 0.10046300706738066, 0.5692903733818238, 0.05581278170410037, 0.1681331616435224, 0.5630019147150315, 0.20441085627200029, 0.02930121489223212, 0.035580046654853294, 0.9102330230413084, 0.24749373725139925, 0.49581245362696985, 0.17902046994517878, 0.03712406058770989, 0.03959899796022388, 0.19989230879125344, 0.02665230783883379, 0.7595907734067631, 0.013326153919416895, 0.9182953777894854, 0.9421331768726572, 0.031404439229088574, 0.031404439229088574, 0.031404439229088574, 0.09553045778284573, 0.019106091556569147, 0.8406680284890424, 0.019106091556569147, 0.14794398755490867, 0.31955901311860274, 0.07693087352855252, 0.05917759502196347, 0.3964898866471553, 0.08223304745436572, 0.14390783304514, 0.03426376977265238, 0.02055826186359143, 0.7195391652256999, 0.7383834924861951, 0.05561849683662248, 0.0345218256227312, 0.14959457769850185, 0.021096671213891287, 0.7309803336129247, 0.13531225491426374, 0.0794224104931548, 0.038240419867074535, 0.014707853795028666, 0.3800504472098736, 0.3156770815586898, 0.09903594715566738, 0.16836111016463454, 0.03713848018337527, 0.9168334319742352, 0.9365255451071544, 0.9669779433240058, 0.08515862868297705, 0.01703172573659541, 0.834554561093175, 0.03406345147319082, 0.03406345147319082, 0.9160575967274505, 0.9175783019850934, 0.04170810463568606, 0.9869284360576358, 0.9662905967165862, 0.19102273278163454, 0.1273484885210897, 0.02829966411579771, 0.6438173586343979, 0.007074916028949428, 0.9374420399288378, 0.030240065804156058, 0.3734906214568229, 0.06725693183322098, 0.5151594778714799, 0.025757973893573993, 0.018602981145358993, 0.9752634784319252, 0.07746914841635266, 0.6376306831192103, 0.21254356103973676, 0.055618875786099344, 0.017877495788389073, 0.9169891332691386, 0.06113260888460924, 0.9236152276471455, 0.9591418052499209, 0.02524057382236634, 0.034682159357115924, 0.7630075058565504, 0.15799650373797255, 0.017983341888874925, 0.026975012833312387, 0.9582985249389543, 0.009256875929715224, 0.6634094416295911, 0.25302127541221614, 0.026227815134193137, 0.047827192303528665, 0.09365087943987915, 0.6135747273647254, 0.17438439619839566, 0.0807335167585165, 0.03713741770891759, 0.046522517758235724, 0.9304503551647145, 0.14036709586723858, 0.1345184668727703, 0.06433491893915103, 0.0467890319557462, 0.6082574154247006, 0.9141713974408536, 0.07032087672621952, 0.014064175345243903, 0.02994325887347686, 0.02994325887347686, 0.9282410250777826, 0.08659413772569775, 0.6992476621350094, 0.14071547380425886, 0.02164853443142444, 0.0541213360785611, 0.2065649134281014, 0.4486005695660788, 0.21073794198220447, 0.054249371203339766, 0.07928754252795811, 0.6852211818561335, 0.159849420339689, 0.10336929181966555, 0.03836386088152535, 0.012787953627175119, 0.8292738286095358, 0.05797355032832621, 0.03528824802593769, 0.06553531776245572, 0.011972798437371717, 0.929651681944184, 0.4111993290531853, 0.12652287047790317, 0.03163071761947579, 0.398547042005395, 0.03163071761947579, 0.9336379867023117, 0.044458951747729125, 0.022229475873864563, 0.9850387285351633, 0.018607563724918685, 0.15351240073057915, 0.08838592769336376, 0.7210430943405991, 0.013955672793689014, 0.20916545730707356, 0.2911678240922331, 0.2994869047805826, 0.043972283638418874, 0.1556856528819695, 0.17059490323037307, 0.02437070046148187, 0.02437070046148187, 0.755491714305938, 0.949036898775405, 0.9527480423772048, 0.14938763794997037, 0.35695782962782396, 0.04717504356314854, 0.4104228789993923, 0.03616753339841388, 0.9227914711004409, 0.3652722635427794, 0.2752403675991366, 0.25466164852630396, 0.07639849455789119, 0.028552972713555294, 0.15704933451737452, 0.25369507883575887, 0.302017950994951, 0.04832287215919216, 0.2375874547826948, 0.9450055902328812, 0.018045008220323913, 0.8403818114036565, 0.07733574951567392, 0.028356441489080435, 0.036090016440647826, 0.9612393473930682, 0.258790229625327, 0.0517580459250654, 0.04528829018443223, 0.6210965511007849, 0.019409267221899527, 0.05798792290431915, 0.9278067664691064, 0.04208230880446135, 0.9258107936981497, 0.9576918658219956, 0.10855366685960621, 0.09304600016537676, 0.775383334711473, 0.01550766669422946, 0.9784463056552996, 0.8846331089361129, 0.026970521613905882, 0.016182312968343528, 0.06472925187337411, 0.010788208645562352, 0.0753881507068244, 0.6481542225403805, 0.22156761366274, 0.025742295363305894, 0.029419766129492448, 0.23641408432113847, 0.2318235195770387, 0.4567611920379277, 0.04361036506894787, 0.03442923558074832, 0.9320420428852924, 0.935940917907228, 0.9068755004786703, 0.18000945098901097, 0.5406805611227902, 0.1774006183659818, 0.054785485083612036, 0.0469589872145246, 0.05203313671572648, 0.0445998314706227, 0.05203313671572648, 0.014866610490207566, 0.8325301874516237, 0.9255184138648035, 0.4851741487134941, 0.15252274091846688, 0.19600207430246422, 0.1138744445771359, 0.052451259320377745, 0.7352958645684918, 0.054982243113297, 0.08943778213096311, 0.10776519650206211, 0.01319573834719128, 0.014702668476259237, 0.9115654455280727, 0.04410800542877771, 0.014702668476259237, 0.014702668476259237, 0.01734451692473999, 0.9192593970112195, 0.03468903384947998, 0.01734451692473999, 0.9524739923670078, 0.9670523926931602, 0.8951785506704202, 0.9612690287292243, 0.9181084682510425, 0.7176147042199251, 0.12954076322594638, 0.04729265959042486, 0.09252911658996169, 0.012337215545328226, 0.006975604498566249, 0.8579993533236486, 0.10463406747849373, 0.020926813495698745, 0.013951208997132498, 0.9692987503360303, 0.8999087966058611, 0.12552958222512628, 0.039941230707994727, 0.02852945050571052, 0.7874128339576103, 0.017117670303426313, 0.9170413221917845, 0.06397962712965938, 0.010663271188276563, 0.010663271188276563, 0.379653396850738, 0.2154410218727848, 0.24561680018069929, 0.08421147434766832, 0.07508856462667092, 0.9423491715090774, 0.6468977222581098, 0.13866457313747962, 0.1435514303405626, 0.05131200063237132, 0.01893657166194656, 0.9340673311966898, 0.0078711292373013, 0.8500819576285402, 0.05509790466110909, 0.04722677542380779, 0.03935564618650649, 0.025515842534885112, 0.025515842534885112, 0.025515842534885112, 0.8930544887209789, 0.9773366684074939, 0.012529957287275562, 0.41760886247198, 0.22798034839031558, 0.10972885927197433, 0.21200041742837758, 0.03302519065467188, 0.03630828669054418, 0.03630828669054418, 0.9077071672636045, 0.03294114702062458, 0.03294114702062458, 0.9223521165774884, 0.9357403814005716, 0.896691785037152, 0.07472431541976267, 0.20640640672711769, 0.41779503706488996, 0.1992889444261826, 0.10818542697421342, 0.06832763808897689, 0.9364847213402224, 0.04274910294672022, 0.9404802648278447, 0.017737831855549786, 0.922367256488589, 0.053213495566649366, 0.017949527304142947, 0.035899054608285894, 0.9333754198154331, 0.017949527304142947, 0.017949527304142947, 0.6988186858789975, 0.07780964359577074, 0.05431993986874561, 0.13066147698157726, 0.03817076855641583, 0.2232945434442656, 0.3188646080384113, 0.31618507351708014, 0.0928905300728145, 0.049124799557738436, 0.925390007755555, 0.9719791623127917, 0.24423208488318757, 0.4138554127655058, 0.15750737589072408, 0.1396522887452169, 0.04527539954753607, 0.8249476780443806, 0.07438052834826384, 0.040571197280871184, 0.045079108089856865, 0.01352373242695706, 0.6588470297115595, 0.1461352434322632, 0.07678292451525694, 0.09783630704363384, 0.01981494826200179, 0.09026784423334921, 0.32574917701599937, 0.1530628663087226, 0.05102095543624086, 0.3767701324522402, 0.6949767029289815, 0.13648990937265443, 0.11928844134212813, 0.02692403691734553, 0.022436697431121276, 0.953339858496827, 0.02325219167065432, 0.7601965486940663, 0.05735498257410475, 0.1001281899175049, 0.06999252110738206, 0.011665420184563678, 0.3190312935866047, 0.3142410339231421, 0.19256843847119381, 0.15137220536541604, 0.023951298317312665, 0.4495206413356106, 0.19393802707853772, 0.27774696020890577, 0.04848450676963443, 0.029783339872775434, 0.9373364862346915, 0.926825810577499, 0.6484465924063346, 0.0493271575840001, 0.2003915776850004, 0.09043312223733352, 0.012331789396000025, 0.9587661407842673, 0.06598373385898224, 0.9237722740257513, 0.010655792978060297, 0.04262317191224119, 0.9057424031351252, 0.03196737893418089, 0.010655792978060297, 0.33856049224911, 0.37209546197662985, 0.20120981836511911, 0.052799739570988706, 0.03531874471302623, 0.09494857003910626, 0.7057843706240232, 0.13292799805474875, 0.04747428501955313, 0.015824761673184376, 0.01588907765975385, 0.2542252425560616, 0.7308975723486771, 0.2199325902890683, 0.4577782422306399, 0.2056684856398527, 0.060705375600150074, 0.05606124850505663, 0.5429819544897047, 0.18018371517201728, 0.17197973488593893, 0.08416676071272983, 0.020813801836902502, 0.9487543565988958, 0.5438143446514343, 0.163748293000761, 0.17470958583824361, 0.08813774240751342, 0.029752080558881434, 0.9541878224093127, 0.041486427061274464, 0.8889797438777819, 0.026669392316333456, 0.05333878463266691, 0.00888979743877782, 0.026669392316333456, 0.18645453969379464, 0.28268914082607577, 0.1323225765568865, 0.05413196313690812, 0.3428357665337514, 0.08257240064922629, 0.08257240064922629, 0.8050809063299563, 0.041286200324613144, 0.8842303334714088, 0.016027966401136125, 0.28850339522045026, 0.016027966401136125, 0.6571466224465812, 0.02404194960170419, 0.9257611119861907, 0.01446501737478423, 0.01446501737478423, 0.04339505212435269, 0.01360899227192014, 0.3048414268910111, 0.6369008383258625, 0.008165395363152084, 0.03810517836137639, 0.9693217518116303, 0.047324230904928426, 0.735215730130138, 0.07774695077238242, 0.11493027505482617, 0.025352266556211655, 0.9141389429557547, 0.9641158796878191, 0.9411028868688621, 0.14427670729862785, 0.17185901898807143, 0.02121716283803351, 0.02333887912183686, 0.6386366014248086, 0.9580382140416043, 0.925859064990478, 0.958867627029682, 0.9337105401476147, 0.054924149420447925, 0.9698275744393539, 0.048491378721967696, 0.8725758229724965, 0.017991254081907142, 0.035982508163814285, 0.062969389286675, 0.008995627040953571, 0.9142910139580672, 0.04155868245263942, 0.9584421273949553, 0.10146087338104852, 0.020292174676209706, 0.8522713364008077, 0.020292174676209706, 0.9127599913730552, 0.06870236494205792, 0.009814623563151131, 0.009814623563151131, 0.9487779894323701, 0.04125121693184218, 0.035077322315469533, 0.6986233361164348, 0.19584838292803822, 0.026307991736602147, 0.04676976308729271, 0.8372023714243921, 0.05073953766208437, 0.07610930649312656, 0.025369768831042184, 0.005073953766208437, 0.9581717462071687, 0.9782233550716433, 0.9259550490885986, 0.9416626752411871, 0.8573144452352657, 0.07144287043627214, 0.0158761934302827, 0.023814290145424046, 0.0317523868605654, 0.944115139199133, 0.9448258648375858, 0.9624557956580454, 0.10611040874173074, 0.8842534061810895, 0.19891418845550163, 0.53852377850148, 0.1297793790532846, 0.10552155119285758, 0.027896502039491084, 0.05035523053731514, 0.9063941496716725, 0.23579050362181783, 0.043868000673826575, 0.06031850092651154, 0.021934000336913288, 0.6360860097704853, 0.02681366489057537, 0.9384782711701379, 0.031312461535077885, 0.10959361537277261, 0.031312461535077885, 0.8141239999120251, 0.015656230767538942, 0.014558149123997381, 0.058232596495989525, 0.058232596495989525, 0.8589307983158455, 0.17682452316032882, 0.5474567157732214, 0.18281857479288233, 0.03796232700617229, 0.05594448190383284, 0.9385864780440241, 0.024411649988199783, 0.024411649988199783, 0.9276426995515918, 0.9450694113842447, 0.027001983182406993, 0.40366061048497826, 0.33447651100752707, 0.13056548096872364, 0.1001348808226267, 0.031210871944714814, 0.5507221844845616, 0.1508645014466799, 0.11014443689691232, 0.14752679123768256, 0.04005252250796812, 0.12004699369128424, 0.16806579116779793, 0.06002349684564212, 0.02400939873825685, 0.624244367194678, 0.22153232267264536, 0.30388203424205806, 0.36651420923851274, 0.07191101573667022, 0.03595550786833511, 0.19441702964894547, 0.3598559112472351, 0.3324583894538878, 0.06954755532157399, 0.043203784366432324, 0.03079219846988586, 0.9545581525664616, 0.03079219846988586, 0.4410367381224825, 0.14730627053290915, 0.19714342194074969, 0.1843533565351977, 0.02999049819232881, 0.692043391852655, 0.0661422002832626, 0.16168093402575304, 0.06981676696566608, 0.009798844486409275, 0.918365905510538, 0.05847712957336366, 0.9356340731738185, 0.9412020021196392, 0.04396985386003868, 0.7189071106116325, 0.19786434237017408, 0.01099246346500967, 0.028580405009025145, 0.03228135759698543, 0.8877373339170993, 0.06456271519397086, 0.016140678798492715, 0.9390862009521129, 0.015522085966150628, 0.015522085966150628, 0.02328312894922594, 0.007761042983075314, 0.019009335014370823, 0.03168222502395137, 0.9314574157041704, 0.012672890009580549, 0.0063364450047902745, 0.6143569498395645, 0.1744857323523933, 0.09507905176088498, 0.076272206357633, 0.03970334029575417, 0.02014603048778271, 0.9267174024380046, 0.02014603048778271, 0.04029206097556542, 0.6414032410799418, 0.10483776017651716, 0.14269584024025947, 0.08809284014832346, 0.02402532004045185, 0.8644717847975213, 0.06946648270694368, 0.042451739432021136, 0.011577747117823946, 0.015436996157098594, 0.9221277524408085, 0.9303765184673861, 0.9443476344861403, 0.23620966170057955, 0.14172579702034774, 0.11023117546027046, 0.5039139449612364, 0.01574731078003864, 0.07181641624540006, 0.2920534260646269, 0.5936823742953071, 0.01915104433210668, 0.023938805415133352, 0.10134855345815787, 0.34965250943064463, 0.48647305659915774, 0.026350623899121045, 0.035471993710355254, 0.022435701250002025, 0.1794856100000162, 0.022435701250002025, 0.7852495437500708, 0.9495694522148305, 0.05223123276816134, 0.713069873443594, 0.14306815932148542, 0.07039861807882615, 0.022709231638331016, 0.08082843039915967, 0.8891127343907564, 0.04432611760783697, 0.9308484697645765, 0.005774289478628283, 0.15590581592296363, 0.8084005270079596, 0.017322868435884847, 0.008661434217942424, 0.9410412958863276, 0.14738139058135333, 0.5012463537538413, 0.2618451101699171, 0.05536153757878247, 0.0344139287651891, 0.18464800197304498, 0.3465561022252716, 0.29016114595764214, 0.11278991253525901, 0.06549091695595684, 0.4710179272698904, 0.2775836508736709, 0.1366061273984601, 0.0677566391896362, 0.04753893233466411, 0.36270213508870974, 0.30617712702293676, 0.11493418306707165, 0.09891876411510266, 0.11587626653483453, 0.9655758863089562, 0.022455253169975726, 0.022455253169975726, 0.93411579981323, 0.44818075481707303, 0.04268388141114981, 0.04268388141114981, 0.46342499817819793, 0.0030488486722249864, 0.020528653832908944, 0.9443180763138115, 0.020528653832908944, 0.009325638649001088, 0.8890442178714371, 0.05906237811034022, 0.02175982351433587, 0.018651277298002176, 0.1772946883782096, 0.33546936134308286, 0.18424742125578644, 0.21032016954669963, 0.09212371062789322, 0.5172805445225496, 0.2583651230354649, 0.16123744632458192, 0.05062745754901549, 0.012381715161444005, 0.8662440136125649, 0.04465175327899819, 0.017860701311599277, 0.06251245459059747, 0.008930350655799639, 0.9263900793441215, 0.06132719873546954, 0.9199079810320431, 0.05041483574286741, 0.37306978449721884, 0.06553928646572764, 0.4537335216858067, 0.055456319317154154, 0.04394174358132283, 0.9227766152077794, 0.9187477846183227, 0.0415544672576234, 0.9557527469253381, 0.1820015375859381, 0.0606671791953127, 0.0606671791953127, 0.6794724069875022, 0.02426687167812508, 0.12209141873679194, 0.5979987856495932, 0.1993329285498644, 0.023670785265296396, 0.05606238615464936, 0.007616202566500522, 0.022848607699501564, 0.9520253208125652, 0.022848607699501564, 0.2166276293280862, 0.523631753694323, 0.16005608281565606, 0.06898969086881726, 0.030355463982279597, 0.1775228410290929, 0.026628426154363935, 0.05325685230872787, 0.7455959323221902, 0.01895647988285328, 0.8476254576190108, 0.11103081074242634, 0.008124205664079976, 0.013540342773466626, 0.9479793520415156, 0.41551400411268385, 0.10240713415808356, 0.44729552850657184, 0.021187682929258666, 0.012948028456769185, 0.44069190587748575, 0.14670993295156096, 0.30185147124516565, 0.08094341128361983, 0.029791672208554523, 0.07218319935919101, 0.2844867268862234, 0.15285853981946332, 0.3991306317508209, 0.09341355211189425, 0.012030957256195995, 0.09624765804956796, 0.8902908369585036, 0.020426088114017613, 0.45754437375399454, 0.01634087049121409, 0.04902261147364227, 0.46162959137679804, 0.7813186897724644, 0.04972028025824774, 0.07635614468230903, 0.06747752320762193, 0.026635864424061288, 0.0487471848605644, 0.26810951673310424, 0.0974943697211288, 0.0121867962151411, 0.5727794221116318, 0.014755136920809412, 0.929573626010993, 0.029510273841618823, 0.029510273841618823, 0.014755136920809412, 0.4597195250218296, 0.2921992679947591, 0.17081573749317683, 0.044488986292435126, 0.032405557916712006, 0.04487547047449283, 0.6968896591333004, 0.14782507921009402, 0.036956269802523506, 0.07391253960504701, 0.0412580654583706, 0.32711751899136693, 0.5363548509588179, 0.0559930888363601, 0.0383110607827727, 0.9578597416357291, 0.9633611716473747, 0.03758962910054016, 0.9021510984129638, 0.9354247387132715, 0.20701617647477383, 0.06900539215825793, 0.0627321746893254, 0.6586878342379167, 0.00627321746893254, 0.3309112505802461, 0.21155449281156125, 0.2887432942428066, 0.11578320214686798, 0.05360333432725369, 0.01215388291092656, 0.8993873354085654, 0.02430776582185312, 0.02430776582185312, 0.036461648732779676, 0.9507631851348001, 0.9088018120224017, 0.03994733239658909, 0.019973666198294545, 0.029960499297441816, 0.9303036738721868, 0.029071989808505838, 0.029071989808505838, 0.6556404708894958, 0.1325642064140514, 0.09887080395048, 0.05081627912538637, 0.061863296326557314, 0.9577903929143392, 0.19426506586108575, 0.5509664579788985, 0.17231421096152802, 0.03841399607422599, 0.043901709799115424, 0.8081031388843439, 0.05285062722661321, 0.03750689674146744, 0.09035752396808065, 0.011934012599557823, 0.8110851382583304, 0.058272136146714996, 0.07717120732943338, 0.03464829716831702, 0.01732414858415851, 0.04563801357355465, 0.06845702036033198, 0.8899412646843158, 0.07140785248923112, 0.3044229500856695, 0.06107250541842135, 0.02536857917380579, 0.5374380476821079, 0.914113724423364, 0.03054691282210262, 0.8308760287611913, 0.1130235774417797, 0.009164073846630786, 0.018328147693261573, 0.9369294802813781, 0.03230791311315097, 0.9524626489753893, 0.8463939529951192, 0.04676209685055907, 0.05728356864193486, 0.02455010084654351, 0.02455010084654351, 0.04964572135393254, 0.8368850171091485, 0.05673796726163719, 0.042553475446227895, 0.021276737723113948, 0.8393725510565745, 0.09149558613412898, 0.0358026206611809, 0.023868413774120602, 0.011934206887060301, 0.004688845559632635, 0.13597652122934642, 0.8064814362568132, 0.02813307335779581, 0.023444227798163172, 0.9001438618918761, 0.032147995067567006, 0.04420349321790463, 0.004018499383445876, 0.016073997533783503, 0.9367366471597653, 0.7663557782599596, 0.09109138449601588, 0.09505187947410353, 0.03069383608017926, 0.015841979912350587, 0.11179772562929104, 0.6518146185174423, 0.1558392539074966, 0.041331280384162145, 0.03929859446362958, 0.8936322846557222, 0.979605335649667, 0.9050840036543472, 0.03120979322946025, 0.03120979322946025, 0.03120979322946025, 0.015604896614730124, 0.4053588898573823, 0.29480646535082344, 0.2300543309969819, 0.019478284317822264, 0.05027503114464936, 0.03226312925262987, 0.2365962811859524, 0.010754376417543291, 0.021508752835086582, 0.6882800907227706, 0.7659258761114482, 0.10833819958155352, 0.060467832324588015, 0.05290935328401451, 0.015116958081147004, 0.1531581143105723, 0.11486858573292923, 0.038289528577643075, 0.6764483382050277, 0.012763176192547692, 0.9558963117296999, 0.9144415445928682, 0.059317356986991816, 0.8897603548048773, 0.020112721052058465, 0.06033816315617539, 0.8145652026083678, 0.04022544210411693, 0.07039452368220463, 0.7761107721160172, 0.098515608844448, 0.040847935374527224, 0.07689023129322771, 0.007208459183740098, 0.29332970879340886, 0.33069655067791953, 0.2329199810801166, 0.05605026282676603, 0.08718929773052493, 0.13501575356371726, 0.3660065608654986, 0.07645470382523749, 0.029280524869239887, 0.3936603899086696, 0.3079484144084793, 0.27670727091776404, 0.17852081994694452, 0.22612637193279642, 0.011901387996462969, 0.12786255586209877, 0.73614073423519, 0.053379513612332494, 0.057103665724820805, 0.02482768074992209, 0.3674886115550865, 0.17293581720239365, 0.09727639717634642, 0.12159549647043304, 0.24048887079707867, 0.9557553337962457, 0.029216448078704337, 0.17529868847222602, 0.014608224039352169, 0.014608224039352169, 0.774235874085665, 0.9706080174136861, 0.8985803285493275, 0.038237460789333086, 0.04620359845377747, 0.007966137664444392, 0.01115259273022215, 0.5419014599238062, 0.1101667803141804, 0.1161217414122442, 0.21437859953029698, 0.017864883294191416, 0.8310895742300233, 0.025724201107119767, 0.12070586673340815, 0.009893923502738372, 0.011872708203286047, 0.9003368385651698, 0.1516852064131333, 0.45791760426606276, 0.2861985026662892, 0.07584260320656665, 0.0279043540099632, 0.9464882241177446, 0.04027609464330828, 0.02408694383727339, 0.1926955506981871, 0.7707822027927484, 0.9601076772710313, 0.6344484798237725, 0.10482872539628299, 0.12595093125971316, 0.11343406852582862, 0.021904509784297938, 0.723734647825611, 0.07202213728361663, 0.10188497469389671, 0.08256196225195077, 0.019323012441945925, 0.3160840640107601, 0.0729424763101754, 0.22423057532387256, 0.3755186743375697, 0.010806292786692652, 0.09041985820001495, 0.7145867898045958, 0.14035321272838142, 0.03441352812090121, 0.020243251835824243, 0.9508702166588083, 0.950543670372428, 0.9179738057597485, 0.015236079763647279, 0.02285411964547092, 0.04189921935003002, 0.0038090199409118197, 0.08493599559541923, 0.8493599559541923, 0.05662399706361282, 0.27407658640076055, 0.4697251034622265, 0.13071344889882425, 0.09698094595719219, 0.028672627500387255, 0.3479653645384795, 0.3882992673042364, 0.15108122900393706, 0.08408593288454416, 0.028028644294848054, 0.971474653522973, 0.9385318714727781, 0.038081388458409915, 0.9139533230018381, 0.20538025040214514, 0.3956801327677691, 0.2834151707181117, 0.08425856426754672, 0.030878848836686155, 0.9650129252208772, 0.8841392248854454, 0.0319568394536908, 0.04260911927158773, 0.021304559635793866, 0.021304559635793866, 0.10872822839108748, 0.8698258271286998, 0.9389695949188541, 0.02470972618207511, 0.02470972618207511, 0.026617403011757867, 0.9582265084232832, 0.44074545611301974, 0.2245958988032374, 0.1812124174959454, 0.13744501157531452, 0.01612483376023243, 0.044860886849975724, 0.044860886849975724, 0.9420786238494903, 0.11392388666490823, 0.03797462888830275, 0.018987314444151374, 0.8354418355426604, 0.9082588281893625, 0.0367212171464311, 0.9547516458072084, 0.9227494906757541, 0.9615917756771335, 0.9632817252812423, 0.9126753951471017, 0.9142000134882191, 0.8694721915979066, 0.11021478485043887, 0.01224608720560432, 0.059432875500694315, 0.059432875500694315, 0.029716437750347158, 0.8320602570097204, 0.029716437750347158, 0.04390855703576296, 0.9220796977510222, 0.19211936182896447, 0.23762131594635078, 0.48409023408219337, 0.04613392570235002, 0.03981420985271303, 0.1931698798369969, 0.5309314152916276, 0.15716484306264542, 0.08629778655439803, 0.03257598565298469, 0.01401217465765476, 0.8827670034322499, 0.0700608732882738, 0.02802434931530952, 0.01401217465765476, 0.04638847771212155, 0.12756831370833424, 0.6726329268257625, 0.023194238856060773, 0.13916543313636465, 0.018606656072913657, 0.07442662429165463, 0.8559061793540281, 0.037213312145827314, 0.018606656072913657, 0.9764252454542596, 0.08189971455607487, 0.5809979750559157, 0.20439928761003298, 0.10289964136532483, 0.02939989753294995, 0.021173400170848424, 0.10586700085424211, 0.12704040102509054, 0.7198956058088464, 0.021173400170848424, 0.1245757104939368, 0.5373647173001173, 0.1995322820623225, 0.10873981509216517, 0.029560338083307037, 0.9695483945563813, 0.02909990488621427, 0.9311969563588567, 0.948801635071246, 0.9784338000406644, 0.020601032074048634, 0.020601032074048634, 0.9476474754062372], \"Term\": [\"$\", \"$\", \"$\", \"$\", \"$\", \"a.m.\", \"accent\", \"accomodate\", \"acrylic\", \"adjustment\", \"adjustment\", \"alex\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"ami\", \"apartment\", \"apartment\", \"apartment\", \"apartment\", \"appetizer\", \"appetizer\", \"appetizer\", \"appetizer\", \"appetizer\", \"appliance\", \"arcade\", \"area\", \"area\", \"area\", \"area\", \"area\", \"arepa\", \"art\", \"art\", \"art\", \"art\", \"art\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"avec\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bagel\", \"bagel\", \"bagel\", \"bagel\", \"bakersfield\", \"balsamic\", \"balsamic\", \"balsamic\", \"balsamic\", \"barber\", \"barber\", \"barber\", \"barber\", \"bathroom\", \"bathroom\", \"bathroom\", \"bathroom\", \"bathroom\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"beef\", \"beef\", \"beef\", \"beef\", \"beef\", \"beer\", \"beer\", \"beer\", \"beer\", \"beer\", \"big\", \"big\", \"big\", \"big\", \"big\", \"bikini\", \"biryani\", \"blind\", \"boba\", \"boba\", \"boba\", \"boba\", \"boba\", \"bouchon\", \"braise\", \"braise\", \"brake\", \"broken\", \"broth\", \"broth\", \"broth\", \"broth\", \"broth\", \"brulee\", \"brulee\", \"burger\", \"burger\", \"burger\", \"burger\", \"burger\", \"burro\", \"business\", \"business\", \"business\", \"business\", \"business\", \"bust\", \"bust\", \"cabinet\", \"cajun\", \"cajun\", \"call\", \"call\", \"call\", \"call\", \"call\", \"canal\", \"car\", \"car\", \"car\", \"car\", \"car\", \"care\", \"care\", \"care\", \"care\", \"care\", \"carnita\", \"carnita\", \"casino\", \"casino\", \"casino\", \"casino\", \"casino\", \"cat\", \"cat\", \"cat\", \"chai\", \"chai\", \"chai\", \"charge\", \"charge\", \"charge\", \"charge\", \"charge\", \"check\", \"check\", \"check\", \"check\", \"check\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chimichanga\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chorizo\", \"chorizo\", \"chorizo\", \"cirque\", \"class\", \"class\", \"class\", \"class\", \"class\", \"clean\", \"clean\", \"clean\", \"clean\", \"clean\", \"coast\", \"coast\", \"coast\", \"coast\", \"cobbler\", \"coca\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"cola\", \"come\", \"come\", \"come\", \"come\", \"come\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"comme\", \"company\", \"company\", \"company\", \"company\", \"company\", \"contractor\", \"cookie\", \"cookie\", \"cookie\", \"cookie\", \"cookie\", \"corned\", \"corned\", \"cox\", \"cox\", \"crema\", \"cupcake\", \"cupcake\", \"cupcake\", \"cupcake\", \"curly\", \"curry\", \"curry\", \"curry\", \"curry\", \"curry\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"dang\", \"danny\", \"dans\", \"day\", \"day\", \"day\", \"day\", \"day\", \"de\", \"de\", \"de\", \"de\", \"de\", \"dedicated\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"dentist\", \"dentist\", \"dentist\", \"dentist\", \"dentist\", \"department\", \"department\", \"department\", \"department\", \"deposit\", \"des\", \"desperate\", \"din\", \"disgust\", \"dish\", \"dish\", \"dish\", \"dish\", \"dish\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"dolphin\", \"dont\", \"donut\", \"donut\", \"donut\", \"donut\", \"donut\", \"dr\", \"dr\", \"dr\", \"dr\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"dunkin\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"eclectic\", \"email\", \"email\", \"email\", \"email\", \"email\", \"en\", \"en\", \"en\", \"en\", \"enchilada\", \"enchilada\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoy\", \"est\", \"est\", \"est\", \"et\", \"et\", \"et\", \"exam\", \"exhibit\", \"exhibit\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"explanation\", \"extension\", \"extension\", \"eyebrow\", \"eyebrow\", \"eyebrow\", \"facial\", \"facial\", \"facial\", \"facial\", \"facial\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"festival\", \"fi\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fish\", \"fish\", \"fish\", \"fish\", \"fish\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"food\", \"food\", \"food\", \"food\", \"food\", \"ford\", \"ford\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"froyo\", \"frustration\", \"fry\", \"fry\", \"fry\", \"fry\", \"fry\", \"gabi\", \"gallery\", \"gallery\", \"gel\", \"gel\", \"gel\", \"gel\", \"gel\", \"get\", \"get\", \"get\", \"get\", \"get\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"gluten\", \"gluten\", \"gluten\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"google\", \"great\", \"great\", \"great\", \"great\", \"great\", \"grub\", \"grub\", \"guacamole\", \"guacamole\", \"guacamole\", \"guacamole\", \"guacamole\", \"guest\", \"guest\", \"guest\", \"guest\", \"guest\", \"guide\", \"guide\", \"guide\", \"guide\", \"gumbo\", \"gym\", \"gym\", \"gym\", \"gym\", \"gym\", \"gyro\", \"gyro\", \"gyro\", \"gyro\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"heartbeat\", \"help\", \"help\", \"help\", \"help\", \"help\", \"hiking\", \"horchata\", \"horribly\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"howard\", \"humor\", \"id\", \"ikea\", \"ikea\", \"in\", \"in\", \"indian\", \"indian\", \"indian\", \"indian\", \"indian\", \"installation\", \"installation\", \"installer\", \"instructor\", \"instructor\", \"instructor\", \"instructor\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"iphone\", \"iphone\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"italian\", \"italian\", \"italian\", \"italian\", \"italian\", \"j'ai\", \"jalape\\u00f1os\", \"jamba\", \"jambalaya\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"japanese\", \"je\", \"johnny\", \"katie\", \"keg\", \"keg\", \"know\", \"know\", \"know\", \"know\", \"know\", \"l\", \"l\", \"la\", \"la\", \"la\", \"la\", \"la\", \"lash\", \"lash\", \"latte\", \"latte\", \"latte\", \"latte\", \"latte\", \"le\", \"le\", \"le\", \"le\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"lentil\", \"les\", \"les\", \"les\", \"library\", \"library\", \"like\", \"like\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lobby\", \"lobby\", \"lobby\", \"lobby\", \"lobby\", \"long\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"loss\", \"loss\", \"loss\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lunch\", \"lunch\", \"lunch\", \"lunch\", \"lunch\", \"luxurious\", \"macaron\", \"macaron\", \"mais\", \"manager\", \"manager\", \"manager\", \"manager\", \"manager\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"margarita\", \"margarita\", \"margarita\", \"margarita\", \"margarita\", \"massage\", \"massage\", \"massage\", \"massage\", \"massage\", \"meal\", \"meal\", \"meal\", \"meal\", \"meal\", \"medical\", \"medical\", \"medical\", \"medical\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"mexican\", \"mexican\", \"mexican\", \"mexican\", \"mexican\", \"mic\", \"michelle\", \"mighty\", \"milk\", \"milk\", \"milk\", \"milk\", \"milk\", \"min\", \"min\", \"min\", \"min\", \"min\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"mocha\", \"mocha\", \"mocha\", \"mocha\", \"mojito\", \"month\", \"month\", \"month\", \"month\", \"month\", \"motel\", \"motel\", \"museum\", \"museum\", \"nail\", \"nail\", \"nail\", \"nail\", \"nail\", \"nancy\", \"need\", \"need\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"night\", \"nigiri\", \"nigiri\", \"nigiri\", \"nite\", \"noodle\", \"noodle\", \"noodle\", \"noodle\", \"noodle\", \"nurse\", \"nurse\", \"nurse\", \"office\", \"office\", \"office\", \"office\", \"office\", \"old\", \"old\", \"old\", \"old\", \"old\", \"order\", \"order\", \"order\", \"order\", \"order\", \"oyster\", \"oyster\", \"oyster\", \"oyster\", \"oyster\", \"pakora\", \"pamper\", \"pamper\", \"park\", \"park\", \"park\", \"park\", \"park\", \"pas\", \"pas\", \"passionate\", \"pastor\", \"pastor\", \"pastry\", \"pastry\", \"pastry\", \"pastry\", \"pastry\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicure\", \"people\", \"people\", \"people\", \"people\", \"people\", \"pho\", \"pho\", \"pho\", \"pho\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"physician\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"place\", \"place\", \"place\", \"place\", \"place\", \"play\", \"play\", \"play\", \"play\", \"play\", \"polish\", \"polish\", \"polish\", \"pool\", \"pool\", \"pool\", \"pool\", \"pool\", \"portion\", \"portion\", \"portion\", \"portion\", \"portion\", \"pour\", \"pour\", \"pour\", \"pour\", \"pour\", \"practice\", \"practice\", \"practice\", \"practice\", \"practice\", \"price\", \"price\", \"price\", \"price\", \"price\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"promotion\", \"pt\", \"que\", \"que\", \"quinoa\", \"raman\", \"raman\", \"raman\", \"raman\", \"raman\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"refund\", \"refund\", \"refund\", \"refund\", \"refund\", \"removal\", \"rent\", \"rent\", \"rent\", \"rent\", \"resolve\", \"resolve\", \"resolve\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"reuben\", \"review\", \"review\", \"review\", \"review\", \"review\", \"rice\", \"rice\", \"rice\", \"rice\", \"rice\", \"roll\", \"roll\", \"roll\", \"roll\", \"roll\", \"roof\", \"roof\", \"roof\", \"room\", \"room\", \"room\", \"room\", \"room\", \"rope\", \"rude\", \"rude\", \"rude\", \"rude\", \"rude\", \"rule\", \"rule\", \"rv\", \"salad\", \"salad\", \"salad\", \"salad\", \"salad\", \"sale\", \"sale\", \"sale\", \"sale\", \"sale\", \"salmon\", \"salmon\", \"salmon\", \"salmon\", \"salmon\", \"salon\", \"salon\", \"salon\", \"salon\", \"salon\", \"salsa\", \"salsa\", \"salsa\", \"salsa\", \"salsa\", \"sampling\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scott\", \"scrumptious\", \"seasoned\", \"seasoned\", \"seasoned\", \"seasoned\", \"seasoned\", \"service\", \"service\", \"service\", \"service\", \"service\", \"shower\", \"shower\", \"shower\", \"shower\", \"shower\", \"shrimp\", \"shrimp\", \"shrimp\", \"shrimp\", \"shrimp\", \"slider\", \"slider\", \"slider\", \"slider\", \"slider\", \"sloppy\", \"smog\", \"sont\", \"sont\", \"spa\", \"spa\", \"spa\", \"spa\", \"spa\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"staff\", \"staff\", \"staff\", \"staff\", \"staff\", \"stay\", \"stay\", \"stay\", \"stay\", \"stay\", \"stop\", \"stop\", \"stop\", \"stop\", \"stop\", \"store\", \"store\", \"store\", \"store\", \"store\", \"strip\", \"strip\", \"strip\", \"strip\", \"strip\", \"stunning\", \"suite\", \"suite\", \"suite\", \"suite\", \"suite\", \"sur\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"taco\", \"taco\", \"taco\", \"taco\", \"taco\", \"tai\", \"take\", \"take\", \"take\", \"take\", \"take\", \"tamale\", \"tamale\", \"tan\", \"tan\", \"tan\", \"tartar\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tea\", \"tea\", \"tea\", \"tea\", \"tea\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tenant\", \"terminal\", \"thai\", \"thai\", \"thai\", \"thai\", \"thai\", \"therapist\", \"therapist\", \"therapist\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thrill\", \"tikka\", \"tile\", \"tile\", \"time\", \"time\", \"time\", \"time\", \"time\", \"torta\", \"tortilla\", \"tortilla\", \"tortilla\", \"tortilla\", \"tortilla\", \"tow\", \"tow\", \"trade\", \"trade\", \"trade\", \"trail\", \"trail\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tr\\u00e8s\", \"tr\\u00e8s\", \"tr\\u00e8s\", \"un\", \"un\", \"un\", \"un\", \"und\", \"une\", \"une\", \"uneven\", \"unorganized\", \"urban\", \"van\", \"verify\", \"vet\", \"vet\", \"vet\", \"vietnamese\", \"vietnamese\", \"vietnamese\", \"vietnamese\", \"vietnamese\", \"vous\", \"vous\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warranty\", \"warranty\", \"warranty\", \"warranty\", \"warranty\", \"wash\", \"wash\", \"wash\", \"wash\", \"wash\", \"wax\", \"wax\", \"wax\", \"wax\", \"wax\", \"wi\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workout\", \"workout\", \"workout\", \"workout\", \"workout\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yellowtail\", \"yoga\", \"yoga\", \"yuck\", \"yuk\", \"\\u00e0\", \"\\u00e0\", \"\\u00e0\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 4, 2, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1681326994974258087366835518\", ldavis_el1681326994974258087366835518_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1681326994974258087366835518\", ldavis_el1681326994974258087366835518_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1681326994974258087366835518\", ldavis_el1681326994974258087366835518_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Cell for pyLDAvis visualization\n",
        "# YOUR CODE HERE\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda, corpus, id2word)\n",
        "vis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2cb1397c6a59aa5751d77bad34994f29",
          "grade": false,
          "grade_id": "cell-9b043e992fbd218c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "MWN5YaQo7GU-",
        "outputId": "d23088af-7397-4078-95cc-e3e0896b8214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell for matplotlib visualzation\n",
        "# YOUR CODE HERE\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Let's create a simple line plot\n",
        "x = range(10)  # X values from 0 to 9\n",
        "y = [i ** 2 for i in x]  # Y values are the squares of X values\n",
        "\n",
        "ax.plot(x, y)\n",
        "\n",
        "# Set the title and labels\n",
        "ax.set_title(\"A Simple Line Plot\")\n",
        "ax.set_xlabel(\"X values\")\n",
        "ax.set_ylabel(\"Y values\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Assign the figure (which includes the plot) to visual_plot\n",
        "visual_plot = fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "97e1c557c7e019c69cc2714b055fb767",
          "grade": true,
          "grade_id": "cell-f5fa579a25122b47",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU_DACrU7GU-",
        "outputId": "e04e1416-1961-4fee-ea7f-76c6258d0fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Visible testing\n",
        "assert visual_plot is not None, \"Variable 'visual_plot' is not created.\""
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "toc-autonumbering": false,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}